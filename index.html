<!DOCTYPE html><html lang="en"><head>
	<meta name="generator" content="Hugo 0.152.2">
    <meta charset="utf-8">
<title>Structure and Automate AI Workflows with MLOps</title>
<meta name="description" content="Introduction to ML- and LLM-Ops">

<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><link rel="stylesheet" href="/talk-2025-mlops/reveal-js/dist/reset.css">
<link rel="stylesheet" href="/talk-2025-mlops/reveal-js/dist/reveal.css">
  <link rel="stylesheet" href="/talk-2025-mlops/css/custom-theme.min.f96d10ca3b5f41b4315bb018de34bcf5b99347c92a09993533ce4f444ed31c56.css" id="theme"><link rel="stylesheet" href="/talk-2025-mlops/highlight-js/solarized-dark.min.css">
<link href="https://fonts.googleapis.com/css?family=Roboto Mono" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Oxygen Mono" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Ubuntu Mono" rel="stylesheet">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-4bw+/aepP/YC94hEpVNVgiZdgIC5+VKNBQNGCHeKRQN+PtmoHDEXuppvnDJzQIu9" crossorigin="anonymous">
<link href="https://cdn.jsdelivr.net/gh/DanySK/css-blur-animation/blur.css" rel="stylesheet" crossorigin="anonymous">

<script src="https://kit.fontawesome.com/81ac037be0.js" crossorigin="anonymous"></script>
<script type="text/javascript" src="https://unpkg.com/qr-code-styling@1.5.0/lib/qr-code-styling.js"></script>

  </head>
  <body>
    
    <div class="reveal">
      <div class="slides">
  

    <section>

<section data-shortcode-section="">
<h1 id="structure-and-automate-ai-workflows-with-mlops">Structure and Automate AI Workflows with MLOps</h1>
<p><a href="mailto:giovanni.ciatto@unibo.it">Giovanni Ciatto</a>
<br> Dipartimento di Informatica — Scienza e Ingegneria (DISI), Sede di Cesena,
<br> Alma Mater Studiorum—Università di Bologna</p>
<!-- 




<img src='./front.png' alt='' style='max-width: 95vw; max-height: 50vh; object-fit: contain;'>
 -->
<p><span class="hint">(versione presentazione: 2025-11-10
)</span></p>
</section><section>
<h2 id="link-a-queste-slide">Link a queste slide</h2>
<p><a href="https://gciatto.github.io/talk-2025-mlops/">https://gciatto.github.io/talk-2025-mlops/</a></p>
<div id="ZTI2ZDA3MTYwNWExNjNhN2I0NWQ5MGQyMDJlMjQxYjkyYzI3MTUwYTk5YzRkZTY4MWYyOWIyOTEyMTAwMGZjMg==" style=""></div>
<script type="text/javascript">
    const qrCode = new QRCodeStyling({
        width:  300 ,
        height:  300 ,
        type: "svg",
        data: "%!s(\u003cnil\u003e)",
        image: "https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg",
        dotsOptions: {
            color: "#000000",
            type: "rounded"
        },
        backgroundOptions: {
            color: "#ffffff",
        },
        imageOptions: {
            crossOrigin: "anonymous",
            margin:  10 
        }
    });
    qrCode.append(document.getElementById("ZTI2ZDA3MTYwNWExNjNhN2I0NWQ5MGQyMDJlMjQxYjkyYzI3MTUwYTk5YzRkZTY4MWYyOWIyOTEyMTAwMGZjMg=="));
</script>
<p><a href="?print-pdf&amp;pdfSeparateFragments=false"><i class="fa fa-print" aria-hidden="true"></i> versione stampabile</a></p>
</section>
<section data-noprocess="" data-shortcode-slide="" id="toc">
<h2 id="outline">Outline</h2>
<ol>
<li>
<p>Motivation and Context</p>
<ul>
<li>the ML workflow</li>
<li>the GenAI workflow</li>
<li>need for MLOps, definition, expected benefits</li>
</ul>
</li>
<li>
<p>MLOps with MLflow</p>
<ul>
<li>API, tracking server, backend store, artifact store, setups</li>
<li>interactive usage (notebook)</li>
<li>batch usage + project setup</li>
<li>interoperability with Python libraries</li>
</ul>
</li>
<li>
<p>End-to-end example for classification</p>
</li>
<li>
<p>End-to-end example for LLM agents</p>
</li>
</ol>

</section>
</section><section>
<h2 id="what-is-the-goal-of-a-machine-learning-workflow">What is the <em>goal</em> of a Machine Learning workflow?</h2>
<p>Training a <strong>model</strong> from <em>data</em>, in order to:</p>
<ul>
<li>do <strong>prediction</strong> on <em>unseen data</em>,
<ul>
<li>e.g. spam filter</li>
</ul>
</li>
<li>or <strong>mine</strong> information from it,
<ul>
<li>e.g. profiling customers</li>
</ul>
</li>
<li>or <strong>automate</strong> some operation which is <em>hard to code</em> explicitly
<ul>
<li>e.g. NPCs in video games</li>
</ul>
</li>
</ul>
</section><section>


<section data-shortcode-section="">
<h2 id="what-is-a-model-in-the-context-of-ml-pt-1">What is a <em>model</em> in the context of ML? (pt. 1)</h2>
<p>In <em>statistics</em> (and <em>machine learning</em>) a <strong>model</strong> is a <em>mathematical representation</em> of a real-world process
<br> (commonly attained by <em>fitting</em> a parametric <em>function</em> over a <em>sample</em> of <em>data</em> describing the process)</p>
<p><img src="./model-statistics.webp" alt=""></p>
<p>e.g.: <strong>$f(x) = \beta_0 + \beta_1 x $</strong> where <strong>$f$</strong> is the amount of minutes played, and <strong>$x$</strong> is the age</p>
</section><section>
<h2 id="what-is-a-model-in-the-context-of-ml-pt-2">What is a <em>model</em> in the context of ML? (pt. 2)</h2>
<p>E.g. <strong>neural networks</strong> (NN) are a popular <em>family</em> of models</p>
<div class="container w-100 m-0 p-0">
    <div class="row "><div class="col "><img src="./neuron.png" alt="Functioning of a single neuron" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain;">
<p>Single neuron</p>
</div>
<div class="col "><img src="./neural-network.png" alt="Functioning of a feed-forward neural network" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain;">
<p>(Feed-forward)
<br>
Neural network $\equiv$ cascade of <em>layers</em></p>
</div>
<div class="col "><img src="./nn-zoo.png" alt="Many sorts of neural architectures" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain;">
<p><a href="https://www.asimovinstitute.org/neural-network-zoo/">Many admissible architectures</a>, serving disparate purposes</p>
</div>
</div>
</div>

</section>
</section><section>
<h2 id="what-is-the-outcome-of-a-machine-learning-workflow">What is the <em>outcome</em> of a Machine Learning workflow?</h2>
<ul>
<li>
<p>A <strong>software module</strong> (e.g. a Python object) implementing a <em>mathematical function</em>…</p>
<ul>
<li>e.g. <code>predict(input_data) -&gt; output_data</code></li>
</ul>
</li>
<li>
<p>… commonly <strong>tailored</strong> on a specific <em>data schema</em></p>
<ul>
<li>e.g. customer information + statistics about shopping history</li>
</ul>
</li>
<li>
<p>… which <strong>works</strong> sufficiently <strong>well</strong> w.r.t. <em>test data</em></p>
</li>
<li>
<p>… which must commonly be <strong>integrated</strong> into a much larger <em>software system</em></p>
<ul>
<li>e.g. a web application, a mobile app, etc.</li>
</ul>
</li>
<li>
<p>… which may need to be <strong>re-trained</strong> upon <em>data changes</em>.</p>
</li>
</ul>
</section><section>


<section data-shortcode-section="">
<h2 id="what-are-the-phases-of-a-machine-learning-workflow">What are the <em>phases</em> of a Machine Learning workflow?</h2>
<p>The process of producing a ML model is <strong>not</strong> <em>linear</em> <strong>nor</strong> <em>simple</em>:</p>
<p><img src="./ml-workflow.webp" alt=""></p>
<ul>
<li>there could be <strong>many iterations</strong> (up to reaching <em>satisfactory evaluation</em>)</li>
<li>the whole workflow may be <strong>re-started</strong> upon <em>data changes</em></li>
<li>updates in the model imply further <strong>integration</strong>/deployment <em>efforts</em> in <em>downstream systems</em></li>
</ul>
</section><section>
<h2 id="activities-in-a-typical-ml-workflow">Activities in a typical ML workflow</h2>
<ol>
<li><strong>Problem framing</strong>: define the business/technical goal</li>
<li><strong>Data collection</strong>: acquire raw data</li>
<li><strong>Data preparation</strong>: clean, label, and transform data</li>
<li><strong>Feature engineering</strong>: extract useful variables from data</li>
<li><strong>Model training</strong>: apply ML algorithms to produce candidate models</li>
<li><strong>Experimentation &amp; evaluation</strong>: compare models, tune hyperparameters, measure performance</li>
<li><strong>Model packaging &amp; deployment</strong>: turn the best model into a service or product</li>
<li><strong>Monitoring &amp; feedback</strong>: check performance in production, detect drift, gather new data, trigger retraining</li>
</ol>
<blockquote>
<p>These steps are cyclical, not linear → one often revisits data, retrain, or refine features.</p>
</blockquote>
</section><section>
<h2 id="example-of-ml-workflow">Example of ML workflow</h2>
<blockquote>
<p>Forecast footfall/visits to some office by day/time</p>
</blockquote>
<ul>
<li>useful for staffing and opening hours planning</li>
</ul>
<ol>
<li><strong>Problem framing</strong>: model as a <em>regression</em> task or <em>time-series forecasting</em> task?</li>
<li><strong>Data collection</strong>: gather <em>historical</em> footfall <em>data</em>, calendar events, weather data, etc.</li>
<li><strong>Data preparation</strong>: clean and preprocess data, handle missing values, etc.</li>
<li><strong>Feature engineering</strong>: create <em>relevant features</em> (e.g. day of week, holidays, weather conditions)</li>
<li><strong>Model training</strong>: apply ML algorithms to <em>produce candidate models</em></li>
<li><strong>Experimentation &amp; evaluation</strong>: <em>compare models</em>, tune hyperparameters, measure performance</li>
<li><strong>Model packaging &amp; deployment</strong>: turn the <em>best model</em> into a <em>service</em> or product</li>
<li><strong>Monitoring &amp; feedback</strong>: <em>monitor performance</em> in production, detect <em>drifts</em>, gather new data, trigger <em>retraining</em>
<ul>
<li>new offices or online services may change footfall patterns</li>
</ul>
</li>
</ol>

</section>
</section><section>
<h2 id="how-are-machine-learning-workflows-typically-performed">How are Machine Learning workflows typically performed?</h2>

<div class="container w-100 m-0 p-0">
    <div class="row "><div class="col "><p><img src="example-jupyter-notebook.png" alt=""></p>
</div>
<div class="col "><h3 id="via-notebooks-eg-jupyter">Via Notebooks (e.g. Jupyter)</h3>
<ul>
<li>
<p>✅ Interleave code, textual description, and visualizations</p>
</li>
<li>
<p>✅ Interactive usage, allowing for real-time feedback and adjustments</p>
</li>
<li>
<p>✅ Uniform &amp; easy interface to workstations</p>
</li>
<li>
<p>✅ Easy to save, restore, and share</p>
</li>
<li>
<p>❌ Incentivises manual activities over automatic ones</p>
</li>
</ul>
</div>
</div>
</div>
</section><section>
<h2 id="pitfalls-of-manual-work-in-notebooks">Pitfalls of manual work in notebooks</h2>
<ul>
<li><strong>Non-reproducibility</strong>: hidden state, out-of-order execution, forgotten seeds</li>
<li><strong>Weak provenance</strong>: params, code version, data slice, and metrics not logged</li>
<li><strong>Human-in-the-loop gating</strong>: “print accuracy → eyeball → tweak → rerun”</li>
<li><strong>Fragile artifacts</strong>: models overwritten, files named <code>final_v3.ipynb</code></li>
<li><strong>Environment drift</strong>: “works on my machine” dependencies and data paths</li>
<li><strong>Collaboration pain</strong>: merge conflicts, opaque diffs, reviewability issues</li>
</ul>
</section><section>
<h2 id="example-why-manual-runs-mislead">Example: why manual runs mislead</h2>
<ul>
<li>Run 1: random split → train → print accuracy = 0.82</li>
<li>Tweak hyperparams → rerun only training cell → accuracy = 0.86</li>
<li>Forgot to fix seed / re-run split → different data, different metric</li>
<li>No record of params, code, data; “best” model cannot be justified</li>
</ul>


<span class="fragment ">
  <h3 id="consequences">Consequences</h3>
<ul>
<li>Incomparable results, irreproducible models</li>
<li>Hard to automate, schedule, or roll back</li>
<li>No trace from model → code → data → metrics</li>
</ul>

</span>

</section><section>
<h2 id="comparison-among-ml-and-ordinary-software-projects">Comparison among ML and ordinary software projects</h2>
<h3 id="analogies">Analogies</h3>
<ul>
<li>Both <strong>produce</strong> <em>software modules</em> in the end</li>
<li>Both involve <strong>iterative processes</strong>, where <em>feedback</em> is used to improve the product</li>
<li>Both are driven by <strong>tests</strong>/evaluations</li>
<li>Both may benefit from <strong>automation</strong>
<ul>
<li>… and may <em>lose efficiency</em> when activities are performed manually</li>
</ul>
</li>
</ul>


<span class="fragment ">
  <h3 id="differences">Differences</h3>
<ul>
<li>ML projects depend on <em>data</em> (which <em>changes</em> over time)</li>
<li>Models need <em>training</em> and <em>retraining</em>, not just coding</li>
<li>Performance may <em>degrade</em> in production (data drift, bias, new environments)</li>
<li>Many <em>different expertises</em> are involved (data engineers, software engineers, domain experts, operations)</li>
</ul>

</span>



<span class="fragment ">
  <blockquote>
<p>No structured process $\implies$ ML projects may fail to move from notebooks to real-world use</p>
</blockquote>

</span>

</section><section>
<h2 id="machine-learning-operations-mlops">Machine Learning Operations (<a href="https://en.wikipedia.org/wiki/MLOps">MLOps</a>)</h2>
<blockquote>
<p>The practice of organizing and <strong>automating</strong> the <em>end-to-end</em> process of building, training, deploying, and maintaining <em>machine-learning models</em></p>
</blockquote>


<span class="fragment ">
  <h3 id="expected-benefits">Expected benefits</h3>
<ul>
<li><strong>Reproducibility</strong> → the same code + same data always gives the same model</li>
<li><strong>Automation</strong> → repetitive steps (training, testing, deployment) are handled by pipelines</li>
<li><strong>Scalability</strong> → easier to scale up the training process to more data, bigger models, or more computing resources</li>
<li><strong>Monitoring &amp; governance</strong> → models are tracked, evaluated, and kept under control</li>
<li><strong>Collaboration</strong> → teams work on shared infrastructure, with clear responsibilities</li>
<li><strong>Versioning</strong> → models, data, and code are versioned and traceable</li>
</ul>

</span>

</section><section>
<h2 id="how-does-mlops-support-ml-practitioners">How does MLOps support ML practitioners</h2>
<p>MLOps adds <em>infrastructure</em> + <em>processes</em> + <em>automation</em> to make each step more reliable:</p>
<ul>
<li><strong>Data</strong> → <em>version control</em> for datasets, metadata, lineage tracking</li>
<li><strong>Training</strong> → <em>automated pipelines</em> that reproduce experiments on demand</li>
<li><strong>Evaluation</strong> → <em>systematic tracking</em> of metrics, logs, and artifacts</li>
<li><strong>Deployment</strong> → continuous integration &amp; delivery (<em>CI/CD</em>) for ML models, often with <em>model registries</em></li>
<li><strong>Monitoring</strong> → <em>automated checks</em> for performance, drift, fairness, anomalies</li>
<li><strong>Collaboration</strong> → <em>shared repositories</em>, environments, and documentation so teams can work together</li>
</ul>
</section><section>
<h2 id="what-may-happen-without-mlops">What may happen <strong>without</strong> MLOps</h2>
<ul>
<li><strong>Data</strong> in <em>ad-hoc spreadsheets</em> or <em>local files</em> (no version control)</li>
<li><strong>Training</strong> in <em>personal notebooks</em> (hard to reproduce later)</li>
<li><strong>Model evaluation</strong> is <em>manual</em> and <em>undocumented</em> (hard to compare results)</li>
<li><strong>Deployment</strong> = <em>copy-paste</em> code or manual sharing of a <em>model file</em></li>
<li><strong>Monitoring</strong> is much harder → <em>models silently degrade</em></li>
<li><strong>Collaboration</strong> = <code>“send me your notebook by email”</code></li>
</ul>


<span class="fragment ">
  <h3 id="consequences">Consequences</h3>
<ul>
<li>❌ Fragile, non-reproducible workflows</li>
<li>❌ Long delays when models need updating</li>
<li>❌ Difficulty scaling beyond a single researcher</li>
<li>❌ Low trust from stakeholders (“why did accuracy drop?”)</li>
</ul>

</span>

</section><section>
<h1 id="what-about-generative-ai-workflows">What about Generative AI workflows?</h1>
</section><section>
<h2 id="what-is-the-goal-of-a-generative-ai-workflow">What is the <em>goal</em> of a Generative AI workflow?</h2>
<p>Engineering <em>prompts</em>, <em>tools</em>, <em>vector stores</em>, and <em>agents</em> to constrain and govern the behavior of <strong>pre-trained</strong> (<em>foundation</em>) models, in order to:</p>
<ul>
<li><strong>generate</strong> contents (text, images, code, etc.) for a specific purpose
<ul>
<li>e.g. bring unstructured data into a particular format</li>
<li>e.g. produce summaries, reports, highlights</li>
</ul>
</li>
<li><strong>interpret</strong> unstructured data and <em>grasp information</em> from it
<ul>
<li>e.g. extract entities, relations, sentiments</li>
<li>e.g. answer questions about a document</li>
</ul>
</li>
<li><strong>automate</strong> data-processing tasks which are <em>hard to code</em> explicitly
<ul>
<li>e.g. the task is ill-defined (<code>write an evaluation paragraph for each student's work</code>)</li>
<li>e.g. the task requires mining information from unstructured data (<code>find the parties involved in this contract</code>)</li>
<li>e.g. the task is complex yet too narrow to allow for general purpose coding (<code>plan a vacation itinerary based on user preferences</code>)</li>
</ul>
</li>
<li><strong>interact</strong> with users via <em>natural language</em>
<ul>
<li>e.g. chatbots, virtual assistants</li>
</ul>
</li>
</ul>
</section><section>
<h2 id="lets-explain-the-nomenclature">Let’s explain the nomenclature</h2>
<ul>
<li>
<p><strong>Pre-trained <u>foundation</u> models</strong> (PFM): large neural-networks trained on massive datasets to learn general skills (e.g. ‘understanding’ and generating text, images, code)</p>
<ul>
<li>e.g. GPT, PaLM, LLaMA, etc.</li>
</ul>
</li>
<li>
<p><strong>Prompts</strong>: carefully <em>crafted textual inputs</em> that guide some PFM to produce <em>desired outputs</em></p>
<ul>
<li>prompt <strong>templates</strong> are prompts with <em>named placeholders</em> to be filled with specific data at runtime
<ul>
<li>e.g. <code>Write a summary of the following article: {article_text}</code></li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Tools</strong>: external <em>software components</em> (e.g. APIs, databases, search engines) that can be <em>invoked</em> by PFMs to perform specific tasks or retrieve information</p>
<ul>
<li>e.g. a calculator API, a weather API, a database query interface</li>
</ul>
</li>
<li>
<p><strong>Vector stores</strong>: specialized databases that store and retrieve <em>high-dimensional vectors</em> (embeddings) for the sake of <em>information retrieval</em> via <em>similarity search</em></p>
<ul>
<li>e.g. to support <em>retrieval-augmented generation</em> (RAG)</li>
</ul>
</li>
<li>
<p><strong>Agents</strong>: software systems that <em>orchestrate</em> the interaction between PFMs and tools, enabling dynamic decision-making and task execution based on the context and user input</p>
<ul>
<li>e.g. a chatbot that uses a PFM for conversation and invokes a weather API when asked about the weather</li>
<li>e.g. an assistant that uses a PFM to understand user requests and a database to fetch relevant information</li>
</ul>
</li>
</ul>
</section><section>
<h2 id="what-are-the-outcomes-of-a-generative-ai-workflow">What are the <em>outcomes</em> of a Generative AI workflow?</h2>
<ol start="0">
<li>
<p>FM are commonly <u>not</u> produced in-house, but rather <em>accessed</em> via APIs… yet the choice of <strong>what model(s) to use</strong> is crucial</p>
<ul>
<li>must be available, configured, and most commonly imply <em>costs</em> (per call, per token, etc.)</li>
</ul>
</li>
<li>
<p>A set of <strong>prompt templates</strong> (text files, or code snippets) that are known to work well for the tasks at hand</p>
<ul>
<li>commonly assessed via semi-automatic <em>evaluations</em> on a <em>validation set</em> of inputs</li>
</ul>
</li>
<li>
<p>A set of <strong>tool servers</strong> implementing the <a href="https://modelcontextprotocol.io/docs/getting-started/intro">MCP protocol</a> so that tools can be <em>invoked</em> by PFMs</p>
<ul>
<li>these are <em>software modules</em>, somewhat similar to ordinary Web services, offering one endpoint per tool</li>
</ul>
</li>
<li>
<p>A set of <strong>agents</strong>, implementing the logic to orchestrate the interaction between PFMs and tools</p>
<ul>
<li>these are <em>software modules</em>, commonly implemented via libraries such as <a href="https://python.langchain.com/en/latest/index.html">LangChain</a> or <a href="https://gpt-index.readthedocs.io/en/latest/">LlamaIndex</a></li>
</ul>
</li>
<li>
<p>A set of <strong>vector stores</strong> (if needed), populated with relevant data, and accessible by the agents</p>
<ul>
<li>there are <em>software modules</em>, somewhat similar to ordinary DBMS, offering CRUD operations on data chunks <em>indexed by</em> their <em>embeddings</em></li>
</ul>
</li>
</ol>
</section><section>


<section data-shortcode-section="">
<h2 id="what-are-the-phases-of-a-genai-workflow">What are the <em>phases</em> of a GenAI workflow?</h2>
<p>(Similar to the ML workflow in the sense that the goal is to process data, but different in many details e.g. <em>no training</em> is involved)</p>
<p><img src="./genai-workflow.png" alt=""></p>
<ul>
<li>there could be <strong>many iterations</strong> (e.g. for PFM selection, and prompt tuning)</li>
<li>the whole workflow may be <strong>re-started</strong> upon <em>data changes</em>, or <em>task changes</em>, or new <em>PFM availability</em></li>
<li>the <strong>interplay</strong> between prompts, models, tasks, and data may need to be <em>monitored</em> and <em>adjusted</em> continuously</li>
<li>the <strong>data-flow</strong> between components (agents, PFM, tools, vector stores) may need to be <em>tracked</em> for the sake of <em>debugging</em> and <em>monitoring</em></li>
</ul>
</section><section>
<h2 id="peculiar-activities-in-a-typical-genai-workflow">Peculiar activities in a typical GenAI workflow</h2>
<ol>
<li>
<p><strong>Foundation model selection</strong>: choose the most suitable pre-trained model(s) based on task requirements, performance, cost, data protection, and availability</p>
<ul>
<li>implies trying out prompts (even manually) on different models</li>
</ul>
</li>
<li>
<p><strong>Prompt engineering</strong>: design, test, and refine prompt templates to elicit the desired responses</p>
<ul>
<li>implies engineering variables, lengths, formats, contents, etc</li>
</ul>
</li>
<li>
<p><strong>Evaluations</strong>: establish assertions and metrics to assess PFM responses to prompts (attained by instantiating templates over actual data)</p>
<ul>
<li>somewhat similar to <em>unit tests</em> in ordinary software</li>
<li>important when automatic, as they allow quick evaluations on prompt/model combinations</li>
</ul>
</li>
<li>
<p><strong>Tracking</strong> the <em>data-flow</em> between components (agents, PFM, tools, vector stores) to monitor <em>costs</em>, <em>latency</em>, and to <em>debug</em> unexpected behaviors</p>
<ul>
<li>also useful for the sake of <em>auditing</em> and <em>governance</em></li>
</ul>
</li>
</ol>
</section><section>
<h2 id="example-of-genai-workflow-pt-1">Example of GenAI workflow (pt. 1)</h2>
<blockquote>
<p>Support public officers in managing tenders through a GenAI assistant that understands and compares procurement decisions transparently.</p>
</blockquote>
<ol>
<li>
<p><strong>Problem Framing</strong>:</p>
<ul>
<li><em>Content Generation</em>: draft and justify <em>comparisons</em> among suppliers’ offers vs. technical specs</li>
<li><em>Interpretation</em>: understand regulatory documents and technical language</li>
<li><em>Automation</em>: retrieve relevant laws, norms, and prior tender examples</li>
<li><em>Interaction</em>: enable officers to query and validate results through natural language</li>
</ul>
</li>
<li>
<p><strong>Data Collection</strong>: past tenders’ technical specifications, acts, etc; regulatory documents, etc.</p>
</li>
<li>
<p><strong>Data Preparation</strong>:</p>
<ul>
<li>devise useful data schema &amp; extract relevant data from documents</li>
<li>anonymize sensitive info (suppliers, personal data)</li>
<li>segment documents and index by topic (law, SLA, price table, etc.)</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="example-of-genai-workflow-pt-2">Example of GenAI workflow (pt. 2)</h2>
<ol start="4">
<li>
<p><strong>Prompt Engineering</strong>:</p>
<ol>
<li>design prompt templates for comparison, justification, and Q&amp;A
<ul>
<li>use role-based system prompts (<code>You are a procurement evaluator…</code>)</li>
</ul>
</li>
<li>allocate placeholders for RAG-retrieved data chunks</li>
<li>iterate on template design based on manual tests</li>
</ol>
</li>
<li>
<p><strong>Foundation Model Selection</strong>: multi-lingual? specialized in legal/technical text? cost constraints? support for tools?</p>
</li>
<li>
<p><strong>Vector stores</strong>: storing embeddings for tender documents &amp; specs, legal texts &amp; guidelines, previous evaluation, templates</p>
<ol>
<li>choose embedding model, chunking strategy, and populate vector store</li>
<li>engineer retrieval strategies to fetch relevant chunks</li>
</ol>
</li>
<li>
<p><strong>Tools</strong>:</p>
<ul>
<li>regulation lookup API + tender database query API</li>
<li>report generation out of document templates</li>
<li>automate scoring calculations via spreadsheet or Python scripts generation</li>
</ul>
</li>
<li>
<p><strong>Agents</strong>:</p>
<ol>
<li>exploit LLM to extract structured check-lists out of technical specs</li>
<li>orchestrate RAG, tool invocations, and prompt templates to score each offer</li>
<li>generate comparison reports</li>
<li>…</li>
</ol>
</li>
</ol>

</section>
</section><section>
<h2 id="llm-operations-llmops">LLM Operations (<a href="https://www.databricks.com/it/glossary/llmops">LLMOps</a>)</h2>
<blockquote>
<p>The practice of organizing and <strong>automating</strong> the <em>end-to-end</em> process of building, evaluating, deploying, and maintaining <em>GenAI applications</em></p>
</blockquote>
<br>


<span class="fragment ">
  <h4 id="in-a-nutshell-mlops-for-genai">In a nutshell: <strong>MLOps for GenAI</strong></h4>

</span>

<br>


<span class="fragment ">
  <h3 id="expected-benefits">Expected benefits</h3>
<ul>
<li><strong>Systematicity</strong> → structured processes to manage prompts, tools, and agents</li>
<li><strong>Efficiency</strong> → reuse of components, templates, and evaluations</li>
<li><strong>Scalability</strong> → easier to test, and update individual components (prompt templates, tools, agents)</li>
<li><strong>Monitoring &amp; governance</strong> → components are tracked, evaluated, and kept under control</li>
</ul>

</span>

</section><section>
<h2 id="how-does-llmops-support-genai-practitioners">How does LLMOps support GenAI practitioners</h2>
<p>LLOps adds <em>infrastructure</em> + <em>processes</em> + <em>automation</em> to make each step more reliable:</p>
<ul>
<li><strong>Foundation models</strong> → <em>catalogs</em> of available models, with metadata on capabilities, costs, and usage policies</li>
<li><strong>Provider Gateways</strong> → standardized APIs to access different PFM providers (e.g. OpenAI, HuggingFace) uniformly, without code rewrites</li>
<li><strong>Prompt engineering</strong> → <em>version control</em> for prompt templates, systematic testing frameworks</li>
<li><strong>Tool integration</strong> → <em>standardized protocols</em> (e.g. MCP) and libraries to connect tools with PFMs + <em>gateway technologies</em> to aggregate multiple tools</li>
<li><strong>Agents</strong> → <em>provider-agnostic libraries</em> and frameworks (e.g. LangChain) to build, manage, and orchestrate agents</li>
<li><strong>Vector stores</strong> → <em>standardized interfaces</em> to store and retrieve data chunks via embeddings, with support for <em>multiple backend</em> DBMS</li>
<li><strong>Evaluation &amp; monitoring</strong> → <em>automated</em> frameworks to run <em>evaluations</em>, <em>track performance</em>, and <em>monitor costs</em></li>
</ul>
</section><section>
<h2 id="what-may-happen-without-llmops">What may happen <strong>without</strong> LLMOps</h2>
<ul>
<li>
<p><strong>Foundation models</strong> are <em>hard-coded</em> in the application</p>
<ul>
<li>making it difficult to switch providers or models</li>
</ul>
</li>
<li>
<p><strong>Prompt templates</strong> are <em>scattered</em> in code or documents</p>
<ul>
<li>making it hard to track changes or reuse them</li>
</ul>
</li>
<li>
<p><strong>Tools</strong> are <em>manually integrated</em>, leading to:</p>
<ul>
<li>brittle connections,</li>
<li>lack of observability,</li>
<li>maintenance challenges</li>
</ul>
</li>
<li>
<p><strong>Agents</strong> are <em>ad-hoc scripts</em> that mix logic, PFM calls, and tool invocations</p>
<ul>
<li>making them hard to debug, extend or compose</li>
</ul>
</li>
<li>
<p><strong>Vector stores</strong> are <em>tightly coupled</em> with specific DBMS</p>
<ul>
<li>making it hard to migrate or scale</li>
</ul>
</li>
<li>
<p><strong>Evaluation &amp; monitoring</strong> are <em>manual</em> and <em>sporadic</em> leading to undetected issues, cost overruns, and loss of trust</p>
</li>
</ul>
</section><section>
<h1 id="mlops-and-llmops-with-mlflow">MLOps and LLMOps with <a href="https://mlflow.org/">MLflow</a></h1>
</section><section>
<h2 id="what-is-mlflow">What is MLflow? <a href="https://mlflow.org/">https://mlflow.org/</a></h2>
<p><img src="./mlflow-logo.webp" alt=""></p>
<blockquote>
<p>An <em>open-source</em> Python framework for <strong>MLOps</strong> and (most recently) <strong>LLMOps</strong></p>
</blockquote>
<ul>
<li>usable either in-cloud (e.g. via <a href="https://www.databricks.com/">Databricks</a>) or on-premises (self-hosted)
<ul>
<li>we’ll see the latter setup</li>
</ul>
</li>
</ul>


<span class="fragment ">
  <h3 id="outline">Outline</h3>
<ol>
<li>First, we focus on how to use MLflow for the sake of <em>MLOps</em></li>
<li>Then, we show how MLflow can be used for <em>LLMOps</em> as well</li>
</ol>

</span>

</section><section>
<h2 id="mlflow-for-mlops-main-components-pt-1">MLflow for MLOps: main components pt. 1</h2>
<p><img src="./mlflow-components-mlops.png" alt=""></p>

<div class="container w-100 m-0 p-0">
    <div class="row "><div class="col "><h3 id="provides">Provides</h3>
<ul>
<li><em>UI</em> to visualize and monitor experiments</li>
<li>Facilities to <em>evaluate</em> ML models (metrics and charts)</li>
<li>Python API and command-line support for <em>ML operations</em></li>
</ul>
</div>
<div class="col "><h3 id="how">How</h3>
<ul>
<li>by <em>tracking</em> metadata about datasets, experiments, and models</li>
<li>by <em>serializing</em> and <em>storing</em> models, charts, predictions, metrics, etc.</li>
<li>by facilitating <em>deployment</em> of models <em>as services</em></li>
</ul>
</div>
</div>
</div>
</section><section>
<h2 id="mlflow-for-mlops-main-components-pt-2">MLflow for MLOps: main components pt. 2</h2>
<p><img src="./mlflow-components-mlops-2.jpg" alt=""></p>
</section><section>
<h2 id="mlflows-common-set-ups">MLflow’s common set-ups</h2>
<p><img src="mlflow-architecture-mlops.png" alt=""></p>

<div class="container w-100 m-0 p-0">
    <div class="row "><div class="col "><ol>
<li>Solo development (serverless)</li>
</ol>
</div>
<div class="col "><ol start="2">
<li>Solo development (local server + remote store)</li>
</ol>
</div>
<div class="col "><ol start="3">
<li>Team work (remote server)</li>
</ol>
</div>
</div>
</div>
</section><section>
<h2 id="mlflows-complex-set-up">MLflow’s complex set-up</h2>
<p>Notice that, in set-up 3, there could be up to three servers involved:</p>
<ol>
<li>the <strong>Backend Store</strong> server (a relational DBMS, e.g. PostgreSQL, MySQL, SQLite, etc.) to store <em>metadata</em></li>
<li>the <strong>Artifact Store</strong> server (e.g. S3, Azure Blob Storage, etc.) to store <em>artifacts</em> via some file-system interface</li>
<li>the <strong>MLflow Tracking Server</strong> to provide the UI and API endpoints
<ul>
<li>this is mediating the interaction between users and the two stores</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="mlflows-functioning-overview">MLflow’s functioning overview</h2>
<h3 id="assumptions">Assumptions</h3>
<ol>
<li>Some Python code is in place to perform ML tasks (via common libraries such as <code>scikit-learn</code>, <code>TensorFlow</code>, <code>PyTorch</code>, etc.)</li>
<li>The code is using the MLflow Python API to log metadata about experiments, datasets, models, metrics, etc.</li>
</ol>


<span class="fragment ">
  <h3 id="workflow">Workflow</h3>
<ol start="0">
<li>
<p>Start the Python code</p>
</li>
<li>
<p>The MLflow Python API invoked in the code will actually log all relevant <em>metadata</em> and <em>artifacts</em> as the code runs</p>
<ul>
<li><strong>metadata</strong> $\approx$ experiment id, run id, timings, data schemas, input parameters, hyper-parameters, metric values, etc.</li>
<li><strong>artifact</strong> $\approx$ dataset, model, chart, etc.</li>
</ul>
</li>
<li>
<p>Metadata and artifacts may be stored (depending on the configuration):</p>
<ul>
<li>on the local file system</li>
<li>on a remote backend and artifact store</li>
</ul>
</li>
</ol>

</span>

</section><section>
<h2 id="mlflow-usage-remarks">MLflow usage remarks</h2>
<ul>
<li>
<p><strong>Assumption 2</strong> may require additional effort from the developer(s)</p>
<ul>
<li>this is kept minimal via <a href="https://mlflow.org/docs/3.3.1/ml/tracking/autolog/">auto-logging</a> available for most common ML libraries</li>
</ul>
</li>
<li>
<p><strong>No big constraint</strong> on how to organize the Python code it-self…</p>
</li>
<li>
<p>… but many <strong>benefits</strong> (<em>automatization</em>, reproducibility) may come from organizing the code as an <a href="https://mlflow.org/docs/latest/ml/projects/">MLflow Project</a></p>
<ul>
<li>$\implies$ <em>decomposing</em> the <em>code</em> into multiple scripts</li>
<li>$\implies$ thinking about the <em>parametric aspects</em> of the experiment, and account for <em>command-line arguments</em> accordingly</li>
<li>$\implies$ thinking about the <em>environment</em> where the code will run (e.g. dependencies, libraries, etc.)</li>
<li>we’ll see this aspect later</li>
</ul>
</li>
</ul>
</section><section>


<section data-shortcode-section="">
<h2 id="a-taste-of-mlflows-tracking-api-pt-1">A taste of MLflow’s Tracking API (pt. 1)</h2>
<ol>
<li>
<p>Install MLflow into your Python environment</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>pip install mlflow
</span></span></code></pre></div></li>
<li>
<p>Consider the following dummy script:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">import</span> <span style="color:#000">sys</span> <span style="color:#8f5902;font-style:italic"># to read command-line arguments</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">import</span> <span style="color:#000">tempfile</span> <span style="color:#8f5902;font-style:italic"># to save generated files into temporary directories</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">import</span> <span style="color:#000">mlflow</span> <span style="color:#8f5902;font-style:italic"># to use MLflow functionalities</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">from</span> <span style="color:#000">random</span> <span style="color:#204a87;font-weight:bold">import</span> <span style="color:#000">Random</span> <span style="color:#8f5902;font-style:italic"># to generate random numbers with controlled seed</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Set the experiment name (creates it if it does not exist)</span>
</span></span><span style="display:flex;"><span><span style="color:#000">mlflow</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">set_experiment</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">experiment_name</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"logging_example"</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Read a seed from command-line arguments (default: 42)</span>
</span></span><span style="display:flex;"><span><span style="color:#000">seed</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#204a87">int</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">sys</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">argv</span><span style="color:#000;font-weight:bold">[</span><span style="color:#0000cf;font-weight:bold">1</span><span style="color:#000;font-weight:bold">])</span> <span style="color:#204a87;font-weight:bold">if</span> <span style="color:#204a87">len</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">sys</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">argv</span><span style="color:#000;font-weight:bold">)</span> <span style="color:#ce5c00;font-weight:bold">&gt;</span> <span style="color:#0000cf;font-weight:bold">1</span> <span style="color:#204a87;font-weight:bold">else</span> <span style="color:#0000cf;font-weight:bold">42</span>
</span></span><span style="display:flex;"><span><span style="color:#000">rand</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#000">Random</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">seed</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Start an MLflow run, naming it "example_run" (otherwise random name is generated)</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">with</span> <span style="color:#000">mlflow</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">start_run</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">run_name</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"example_run"</span><span style="color:#000;font-weight:bold">)</span> <span style="color:#204a87;font-weight:bold">as</span> <span style="color:#000">run</span><span style="color:#000;font-weight:bold">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8f5902;font-style:italic"># notice that experiments are runs are identified by their numeric IDs</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87">print</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">f</span><span style="color:#4e9a06">"Started MLflow run with ID: </span><span style="color:#4e9a06">{</span><span style="color:#000">run</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">info</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">run_id</span><span style="color:#4e9a06">}</span><span style="color:#4e9a06"> in experiment ID: </span><span style="color:#4e9a06">{</span><span style="color:#000">run</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">info</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">experiment_id</span><span style="color:#4e9a06">}</span><span style="color:#4e9a06">"</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8f5902;font-style:italic"># Log a parameter "seed" with the given seed value</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">mlflow</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">log_param</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"seed"</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">seed</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8f5902;font-style:italic"># Let's simulate 5 different metric scores to be logged</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">for</span> <span style="color:#000">i</span> <span style="color:#204a87;font-weight:bold">in</span> <span style="color:#204a87">range</span><span style="color:#000;font-weight:bold">(</span><span style="color:#0000cf;font-weight:bold">5</span><span style="color:#000;font-weight:bold">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#000">mlflow</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">log_metric</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">f</span><span style="color:#4e9a06">"random_</span><span style="color:#4e9a06">{</span><span style="color:#000">i</span><span style="color:#4e9a06">}</span><span style="color:#4e9a06">"</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">rand</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">random</span><span style="color:#000;font-weight:bold">())</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">mlflow</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">log_metric</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"random_4"</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">rand</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">randint</span><span style="color:#000;font-weight:bold">(</span><span style="color:#0000cf;font-weight:bold">1</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#0000cf;font-weight:bold">10</span><span style="color:#000;font-weight:bold">))</span> <span style="color:#8f5902;font-style:italic"># overwrite last metric</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8f5902;font-style:italic"># Create and log an example artifact (a text file, generated inside temporaty directory)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">with</span> <span style="color:#000">tempfile</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">TemporaryDirectory</span><span style="color:#000;font-weight:bold">()</span> <span style="color:#204a87;font-weight:bold">as</span> <span style="color:#000">tmpdir</span><span style="color:#000;font-weight:bold">:</span>
</span></span><span style="display:flex;"><span>        <span style="color:#000">file_path</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#4e9a06">f</span><span style="color:#4e9a06">"</span><span style="color:#4e9a06">{</span><span style="color:#000">tmpdir</span><span style="color:#4e9a06">}</span><span style="color:#4e9a06">/example.txt"</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">with</span> <span style="color:#204a87">open</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">file_path</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#4e9a06">"w"</span><span style="color:#000;font-weight:bold">)</span> <span style="color:#204a87;font-weight:bold">as</span> <span style="color:#000">f</span><span style="color:#000;font-weight:bold">:</span>
</span></span><span style="display:flex;"><span>            <span style="color:#000">f</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">write</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"This is an example artifact."</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#000">mlflow</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">log_artifact</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">file_path</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">artifact_path</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"examples"</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8f5902;font-style:italic">#&nbsp;Simulate an error in the run if the seed parameter is odd</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">if</span> <span style="color:#000">seed</span> <span style="color:#ce5c00;font-weight:bold">%</span> <span style="color:#0000cf;font-weight:bold">2</span> <span style="color:#ce5c00;font-weight:bold">==</span> <span style="color:#0000cf;font-weight:bold">1</span><span style="color:#000;font-weight:bold">:</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">raise</span> <span style="color:#c00;font-weight:bold">ValueError</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"Let the run fail for odd seeds!"</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87">print</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"Run completed successfully."</span><span style="color:#000;font-weight:bold">)</span>
</span></span></code></pre></div></li>
</ol>
</section><section>
<h2 id="a-taste-of-mlflows-tracking-api-pt-2">A taste of MLflow’s Tracking API (pt. 2)</h2>
<ol start="3">
<li>
<p>Let’s run the experiment <em>twice</em>, with <strong>different seeds</strong>:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>python logging_example.py <span style="color:#0000cf;font-weight:bold">42</span>
</span></span><span style="display:flex;"><span>python logging_example.py <span style="color:#0000cf;font-weight:bold">43</span>
</span></span></code></pre></div></li>
<li>
<p>The <strong>1st</strong> <em>successful</em> run shall output something like:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>2025/11/10 11:44:49 INFO mlflow.tracking.fluent: Experiment with name 'logging_example' does not exist. Creating a new experiment.
</span></span><span style="display:flex;"><span>Started MLflow run with ID: 378f18735f6d4abd8abeba76f4029bea in experiment ID: 931233098002846893
</span></span></code></pre></div></li>
<li>
<p>The <strong>2nd</strong> <em>failing</em> run shall output something like:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>Started MLflow run with ID: 9b52b7b7416e423ca9c878fba9b5c667 in experiment ID: 931233098002846893
</span></span><span style="display:flex;"><span>Traceback (most recent call last):
</span></span><span style="display:flex;"><span>File "/home/gciatto/Work/Code/example-mlops/mlflow_tracking.py", line 28, in &lt;module&gt;
</span></span><span style="display:flex;"><span>    raise ValueError("Let the run fail for odd seeds!")
</span></span><span style="display:flex;"><span>ValueError: Let the run fail for odd seeds!
</span></span></code></pre></div></li>
<li>
<p>Look at your file system, notice that a new <code>mlruns/</code> folder has appeared next to Python script:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>mlruns
</span></span><span style="display:flex;"><span>├── 931233098002846893
</span></span><span style="display:flex;"><span>│   ├── 378f18735f6d4abd8abeba76f4029bea
</span></span><span style="display:flex;"><span>│   │   ├── artifacts
</span></span><span style="display:flex;"><span>│   │   │   └── examples
</span></span><span style="display:flex;"><span>│   │   │       └── example.txt
</span></span><span style="display:flex;"><span>│   │   ├── meta.yaml
</span></span><span style="display:flex;"><span>│   │   ├── metrics
</span></span><span style="display:flex;"><span>│   │   │   ├── random_0
</span></span><span style="display:flex;"><span>│   │   │   ├── random_1
</span></span><span style="display:flex;"><span>│   │   │   ├── random_2
</span></span><span style="display:flex;"><span>│   │   │   ├── random_3
</span></span><span style="display:flex;"><span>│   │   │   └── random_4
</span></span><span style="display:flex;"><span>│   │   ├── params
</span></span><span style="display:flex;"><span>│   │   │   └── seed
</span></span><span style="display:flex;"><span>│   │   └── tags
</span></span><span style="display:flex;"><span>│   │       ├── mlflow.runName
</span></span><span style="display:flex;"><span>│   │       ├── mlflow.source.git.commit
</span></span><span style="display:flex;"><span>│   │       ├── mlflow.source.name
</span></span><span style="display:flex;"><span>│   │       ├── mlflow.source.type
</span></span><span style="display:flex;"><span>│   │       └── mlflow.user
</span></span><span style="display:flex;"><span>│   ├── 9b52b7b7416e423ca9c878fba9b5c667
</span></span><span style="display:flex;"><span>│   │   ├── artifacts
</span></span><span style="display:flex;"><span>│   │   │   └── examples
</span></span><span style="display:flex;"><span>│   │   │       └── example.txt
</span></span><span style="display:flex;"><span>│   │   ├── meta.yaml
</span></span><span style="display:flex;"><span>│   │   ├── metrics
</span></span><span style="display:flex;"><span>│   │   │   ├── random_0
</span></span><span style="display:flex;"><span>│   │   │   ├── random_1
</span></span><span style="display:flex;"><span>│   │   │   ├── random_2
</span></span><span style="display:flex;"><span>│   │   │   ├── random_3
</span></span><span style="display:flex;"><span>│   │   │   └── random_4
</span></span><span style="display:flex;"><span>│   │   ├── params
</span></span><span style="display:flex;"><span>│   │   │   └── seed
</span></span><span style="display:flex;"><span>│   │   └── tags
</span></span><span style="display:flex;"><span>│   │       ├── mlflow.runName
</span></span><span style="display:flex;"><span>│   │       ├── mlflow.source.git.commit
</span></span><span style="display:flex;"><span>│   │       ├── mlflow.source.name
</span></span><span style="display:flex;"><span>│   │       ├── mlflow.source.type
</span></span><span style="display:flex;"><span>│   │       └── mlflow.user
</span></span><span style="display:flex;"><span>│   ├── meta.yaml
</span></span><span style="display:flex;"><span>│   └── tags
</span></span><span style="display:flex;"><span>│       └── mlflow.experimentKind
</span></span><span style="display:flex;"><span>└── models
</span></span></code></pre></div></li>
</ol>
</section><section>
<h2 id="a-taste-of-mlflows-tracking-api-pt-3">A taste of MLflow’s Tracking API (pt. 3)</h2>
<ol start="7">
<li>
<p>Let’s now start the <strong>MLflow Web UI</strong> via the following command, to <em>visualize</em> the experiment runs:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>mlflow ui
</span></span></code></pre></div><p>then browse to <a href="http://127.0.0.1:5000">http://127.0.0.1:5000</a> in your favorite browser</p>
</li>
<li>
<p>You should see something like the following:
<img src="./mlflow-ui-dummy-1.png" alt=""></p>
</li>
</ol>
</section><section>
<h2 id="a-taste-of-mlflows-tracking-api-pt-4">A taste of MLflow’s Tracking API (pt. 4)</h2>
<ol start="9">
<li>Click on the <strong>experiment name</strong> (<code>logging_example</code>) to see the two runs:
<img src="./mlflow-ui-dummy-2.png" alt="">
<ul>
<li>notice that the <em>latest</em> run is marked as <strong>failing</strong> while the earliest one is successful
<ul>
<li>the <strong>exit code</strong> of the run is registered automatically</li>
</ul>
</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="a-taste-of-mlflows-tracking-api-pt-5">A taste of MLflow’s Tracking API (pt. 5)</h2>
<ol start="10">
<li>You may switch to the <strong>“Chart view”</strong> to see a <em>comparison</em> among the logged <em>metrics</em> (across all runs):
<img src="./mlflow-ui-dummy-2a.png" alt=""></li>
</ol>
</section><section>
<h2 id="a-taste-of-mlflows-tracking-api-pt-6">A taste of MLflow’s Tracking API (pt. 6)</h2>
<ol start="11">
<li>You may click on one <strong>run name</strong> to see details about that run
<img src="./mlflow-ui-dummy-3.png" alt="">
<ul>
<li>notice the logged <em>parameters</em>, <em>metrics</em>, and <em>metadata</em>
<ul>
<li>notice that these are the same information we logged via the MLflow Python API + some automatically-inferred metadata</li>
</ul>
</li>
<li>notice that these data are the same one stored on the file system, in <code>mlruns/</code></li>
</ul>
</li>
</ol>
</section><section>
<h2 id="a-taste-of-mlflows-tracking-api-pt-7">A taste of MLflow’s Tracking API (pt. 7)</h2>
<ol start="12">
<li>You may switch to the <strong>“Modal metrics”</strong> tab to see the logged metrics in graphical form:
<img src="./mlflow-ui-dummy-4.png" alt=""></li>
</ol>
</section><section>
<h2 id="a-taste-of-mlflows-tracking-api-pt-8">A taste of MLflow’s Tracking API (pt. 8)</h2>
<ol start="13">
<li>You may switch to the <strong>“Artifacts”</strong> tab to see the logged artifacts:
<img src="./mlflow-ui-dummy-5.png" alt="">
<ul>
<li>notice that the <code>example.txt</code> artifact is inside some “virtual” <code>examples/</code> folder
<ul>
<li>as we asked explicitly in the Python code</li>
</ul>
</li>
</ul>
</li>
</ol>

</section>
</section><section>
<h1 id="talk-is-over">Talk is Over</h1>
<br>
<p>Compiled on: 2025-11-10
 — <a href="?print-pdf&amp;pdfSeparateFragments=false"><i class="fa fa-print" aria-hidden="true"></i> printable version</a></p>
<p><a href="#toc"><i class="fa fa-undo" aria-hidden="true"></i> back to ToC</a></p>
</section>

  


</div>
      

    </div>
<script type="text/javascript" src="/talk-2025-mlops/reveal-hugo/object-assign.js"></script>

<a href="/talk-2025-mlops/reveal-js/dist/print/" id="print-location" style="display: none;"></a>

<script type="application/json" id="reveal-hugo-site-params">{"custom_theme":"custom-theme.scss","custom_theme_compile":true,"custom_theme_options":{"enablesourcemap":true,"targetpath":"css/custom-theme.css"},"height":"1080","highlight_theme":"solarized-dark","history":true,"mermaid":[{}],"slide_number":true,"theme":"league","transition":"slide","transition_speed":"fast","width":"1920"}</script>
<script type="application/json" id="reveal-hugo-page-params">null</script>

<script src="/talk-2025-mlops/reveal-js/dist/reveal.js"></script>


  
  
  <script type="text/javascript" src="/talk-2025-mlops/reveal-js/plugin/markdown/markdown.js"></script>
  
  <script type="text/javascript" src="/talk-2025-mlops/reveal-js/plugin/highlight/highlight.js"></script>
  
  <script type="text/javascript" src="/talk-2025-mlops/reveal-js/plugin/zoom/zoom.js"></script>
  
  <script type="text/javascript" src="/talk-2025-mlops/reveal-js/plugin/notes/notes.js"></script>
  
  
  <script type="text/javascript" src="/talk-2025-mlops/reveal-js/plugin/notes/notes.js"></script>




<script type="text/javascript">
  
  
  function camelize(map) {
    if (map) {
      Object.keys(map).forEach(function(k) {
        newK = k.replace(/(\_\w)/g, function(m) { return m[1].toUpperCase() });
        if (newK != k) {
          map[newK] = map[k];
          delete map[k];
        }
      });
    }
    return map;
  }

  var revealHugoDefaults = { center: true, controls: true, history: true, progress: true, transition: "slide" };

  var revealHugoPlugins = {
    plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealZoom ]
   };
  var revealHugoSiteParams = JSON.parse(document.getElementById('reveal-hugo-site-params').innerHTML);
  var revealHugoPageParams = JSON.parse(document.getElementById('reveal-hugo-page-params').innerHTML);
  
  var options = Object.assign({},
    camelize(revealHugoDefaults),
    camelize(revealHugoSiteParams),
    camelize(revealHugoPageParams),
    camelize(revealHugoPlugins));
  Reveal.initialize(options);
</script>







  
  

  
  

  
  





    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      }
    };
</script>

<script type="text/javascript" id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-HwwvtgBNo3bZJJLYd8oVXjrBZt8cqVSpeBNS5n7C8IVInixGAoxmnlMuBnhbgrkm" crossorigin="anonymous"></script>

<script>
  if (/.*?(\?|&)print-pdf/.test(window.location.toString())) {
      var ytVideos = document.getElementsByTagName("iframe")
      for (let i = 0; i < ytVideos.length; i++) {
          var videoFrame = ytVideos[i]
          var isYouTube = /^https?:\/\/(www.)youtube\.com\/.*/.test(videoFrame.src)
          if (isYouTube) {
              console.log(`Removing ${videoFrame.src}`)
              var parent = videoFrame.parentElement
              videoFrame.remove()
              var p = document.createElement('p')
              p.append(
                  document.createTextNode(
                      "There was an embedded video here, but it is disabled in the printed version of the slides."
                  )
              )
              p.append(document.createElement('br'))
              p.append(
                  document.createTextNode(
                      `Visit instead ${
                          videoFrame.src
                      } or ${
                          videoFrame.src.replace(
                              /(^https?:\/\/(www.)youtube\.com)\/(embed\/)(\w+).*/,
                              "https://www.youtube.com/watch?v=$4"
                          )
                      }`
                  )
              )
              parent.appendChild(p)
          }
      }
  }
</script>


    
  

</body></html>