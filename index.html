<!DOCTYPE html><html lang="en"><head>
	<meta name="generator" content="Hugo 0.153.1">
    <meta charset="utf-8">
<title>Structure and Automate AI Workflows with MLOps</title>
<meta name="description" content="Introduction to ML- and LLM-Ops">

<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><link rel="stylesheet" href="/talk-2025-mlops/reveal-js/dist/reset.css">
<link rel="stylesheet" href="/talk-2025-mlops/reveal-js/dist/reveal.css">
  <link rel="stylesheet" href="/talk-2025-mlops/css/custom-theme.min.f96d10ca3b5f41b4315bb018de34bcf5b99347c92a09993533ce4f444ed31c56.css" id="theme"><link rel="stylesheet" href="/talk-2025-mlops/highlight-js/solarized-dark.min.css">
<link href="https://fonts.googleapis.com/css?family=Roboto Mono" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Oxygen Mono" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Ubuntu Mono" rel="stylesheet">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-4bw+/aepP/YC94hEpVNVgiZdgIC5+VKNBQNGCHeKRQN+PtmoHDEXuppvnDJzQIu9" crossorigin="anonymous">
<link href="https://cdn.jsdelivr.net/gh/DanySK/css-blur-animation/blur.css" rel="stylesheet" crossorigin="anonymous">

<script src="https://kit.fontawesome.com/81ac037be0.js" crossorigin="anonymous"></script>
<script type="text/javascript" src="https://unpkg.com/qr-code-styling@1.5.0/lib/qr-code-styling.js"></script>

  </head>
  <body>
    
    <div class="reveal">
      <div class="slides">
  

    <section>

<section data-shortcode-section="">
<h1 id="structure-and-automate-ai-workflows-with-mlops-and-llmops">Structure and Automate AI Workflows with MLOps and LLMOps</h1>
<p><a href="mailto:giovanni.ciatto@unibo.it">Giovanni Ciatto</a>
<br> Dipartimento di Informatica — Scienza e Ingegneria (DISI), Sede di Cesena,
<br> Alma Mater Studiorum—Università di Bologna</p>
<!-- 




<img src='./front.png' alt='' style='max-width: 95vw; max-height: 50vh; object-fit: contain;'>
 -->
<p><span class="hint">(version: 2025-12-20
)</span></p>
</section><section>
<h2 id="link-to-these-slides">Link to these slides</h2>
<p><a href="https://gciatto.github.io/talk-2025-mlops/">https://gciatto.github.io/talk-2025-mlops/</a></p>
<div id="NGMzYmMzMDQ0YWM4YjJkYjc4ZWRhODZlNjUwNzFlY2M1MTcyODQ2M2M4YzRlOTdmNDMyZDg1YTJjYmY2YWMxNA==" style=""></div>
<script type="text/javascript">
    const qrCode = new QRCodeStyling({
        width:  300 ,
        height:  300 ,
        type: "svg",
        data: "https://gciatto.github.io/talk-2025-mlops/",
        image: "https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg",
        dotsOptions: {
            color: "#000000",
            type: "rounded"
        },
        backgroundOptions: {
            color: "#ffffff",
        },
        imageOptions: {
            crossOrigin: "anonymous",
            margin:  10 
        }
    });
    qrCode.append(document.getElementById("NGMzYmMzMDQ0YWM4YjJkYjc4ZWRhODZlNjUwNzFlY2M1MTcyODQ2M2M4YzRlOTdmNDMyZDg1YTJjYmY2YWMxNA=="));
</script>
<p><a href="?print-pdf&amp;pdfSeparateFragments=false"><i class="fa fa-print" aria-hidden="true"></i> printable version</a></p>
</section>
<section data-noprocess="" data-shortcode-slide="" id="toc">
<h2 id="outline">Outline</h2>
<ol>
<li>
<p>Motivation and Context</p>
<ul>
<li>the ML workflow</li>
<li>the GenAI workflow</li>
<li>need for MLOps, definition, expected benefits</li>
</ul>
</li>
<li>
<p>MLOps with MLflow</p>
<ul>
<li>API, tracking server, backend store, artifact store, setups</li>
<li>interactive usage (notebook)</li>
<li>batch usage + project setup</li>
<li>interoperability with Python libraries</li>
</ul>
</li>
<li>
<p>End-to-end example for classification</p>
</li>
<li>
<p>End-to-end example for LLM agents</p>
</li>
</ol>

</section>
</section><section>
<h2 id="what-is-the-goal-of-a-machine-learning-workflow">What is the <em>goal</em> of a Machine Learning workflow?</h2>
<p>Training a <strong>model</strong> from <em>data</em>, in order to:</p>
<ul>
<li>do <strong>prediction</strong> on <em>unseen data</em>,
<ul>
<li>e.g. spam filter</li>
</ul>
</li>
<li>or <strong>mine</strong> information from it,
<ul>
<li>e.g. profiling customers</li>
</ul>
</li>
<li>or <strong>automate</strong> some operation which is <em>hard to code</em> explicitly
<ul>
<li>e.g. NPCs in video games</li>
</ul>
</li>
</ul>
</section><section>


<section data-shortcode-section="">
<h2 id="what-is-a-model-in-the-context-of-ml-pt-1">What is a <em>model</em> in the context of ML? (pt. 1)</h2>
<p>In <em>statistics</em> (and <em>machine learning</em>) a <strong>model</strong> is a <em>mathematical representation</em> of a real-world process
<br> (commonly attained by <em>fitting</em> a parametric <em>function</em> over a <em>sample</em> of <em>data</em> describing the process)</p>
<p><img src="./model-statistics.webp" alt=""></p>
<p>e.g.: <strong>$f(x) = \beta_0 + \beta_1 x $</strong> where <strong>$f$</strong> is the amount of minutes played, and <strong>$x$</strong> is the age</p>
</section><section>
<h2 id="what-is-a-model-in-the-context-of-ml-pt-2">What is a <em>model</em> in the context of ML? (pt. 2)</h2>
<p>E.g. <strong>neural networks</strong> (NN) are a popular <em>family</em> of models</p>
<div class="container w-100 m-0 p-0">
    <div class="row "><div class="col "><img src="./neuron.png" alt="Functioning of a single neuron" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain;">
<p>Single neuron</p>
</div>
<div class="col "><img src="./neural-network.png" alt="Functioning of a feed-forward neural network" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain;">
<p>(Feed-forward)
<br>
Neural network $\equiv$ cascade of <em>layers</em></p>
</div>
<div class="col "><img src="./nn-zoo.png" alt="Many sorts of neural architectures" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain;">
<p><a href="https://www.asimovinstitute.org/neural-network-zoo/">Many admissible architectures</a>, serving disparate purposes</p>
</div>
</div>
</div>

</section>
</section><section>
<h2 id="what-is-the-outcome-of-a-machine-learning-workflow">What is the <em>outcome</em> of a Machine Learning workflow?</h2>
<ul>
<li>
<p>A <strong>software module</strong> (e.g. a Python object) implementing a <em>mathematical function</em>…</p>
<ul>
<li>e.g. <code>predict(input_data) -&gt; output_data</code></li>
</ul>
</li>
<li>
<p>… commonly <strong>tailored</strong> on a specific <em>data schema</em></p>
<ul>
<li>e.g. customer information + statistics about shopping history</li>
</ul>
</li>
<li>
<p>… which <strong>works</strong> sufficiently <strong>well</strong> w.r.t. <em>test data</em></p>
</li>
<li>
<p>… which must commonly be <strong>integrated</strong> into a much larger <em>software system</em></p>
<ul>
<li>e.g. a web application, a mobile app, etc.</li>
</ul>
</li>
<li>
<p>… which may need to be <strong>re-trained</strong> upon <em>data changes</em>.</p>
</li>
</ul>
</section><section>


<section data-shortcode-section="">
<h2 id="what-are-the-phases-of-a-machine-learning-workflow">What are the <em>phases</em> of a Machine Learning workflow?</h2>
<p>The process of producing a ML model is <strong>not</strong> <em>linear</em> <strong>nor</strong> <em>simple</em>:</p>
<p><img src="./ml-workflow.webp" alt=""></p>
<ul>
<li>there could be <strong>many iterations</strong> (up to reaching <em>satisfactory evaluation</em>)</li>
<li>the whole workflow may be <strong>re-started</strong> upon <em>data changes</em></li>
<li>updates in the model imply further <strong>integration</strong>/deployment <em>efforts</em> in <em>downstream systems</em></li>
</ul>
</section><section>
<h2 id="activities-in-a-typical-ml-workflow">Activities in a typical ML workflow</h2>
<ol>
<li><strong>Problem framing</strong>: define the business/technical goal</li>
<li><strong>Data collection</strong>: acquire raw data</li>
<li><strong>Data preparation</strong>: clean, label, and transform data</li>
<li><strong>Feature engineering</strong>: extract useful variables from data</li>
<li><strong>Model training</strong>: apply ML algorithms to produce candidate models</li>
<li><strong>Experimentation &amp; evaluation</strong>: compare models, tune hyperparameters, measure performance</li>
<li><strong>Model packaging &amp; deployment</strong>: turn the best model into a service or product</li>
<li><strong>Monitoring &amp; feedback</strong>: check performance in production, detect drift, gather new data, trigger retraining</li>
</ol>
<blockquote>
<p>These steps are cyclical, not linear → one often revisits data, retrain, or refine features.</p>
</blockquote>
</section><section>
<h2 id="example-of-ml-workflow">Example of ML workflow</h2>
<blockquote>
<p>Forecast footfall/visits to some office by day/time</p>
</blockquote>
<ul>
<li>useful for staffing and opening hours planning</li>
</ul>
<ol>
<li><strong>Problem framing</strong>: model as a <em>regression</em> task or <em>time-series forecasting</em> task?</li>
<li><strong>Data collection</strong>: gather <em>historical</em> footfall <em>data</em>, calendar events, weather data, etc.</li>
<li><strong>Data preparation</strong>: clean and preprocess data, handle missing values, etc.</li>
<li><strong>Feature engineering</strong>: create <em>relevant features</em> (e.g. day of week, holidays, weather conditions)</li>
<li><strong>Model training</strong>: apply ML algorithms to <em>produce candidate models</em></li>
<li><strong>Experimentation &amp; evaluation</strong>: <em>compare models</em>, tune hyperparameters, measure performance</li>
<li><strong>Model packaging &amp; deployment</strong>: turn the <em>best model</em> into a <em>service</em> or product</li>
<li><strong>Monitoring &amp; feedback</strong>: <em>monitor performance</em> in production, detect <em>drifts</em>, gather new data, trigger <em>retraining</em>
<ul>
<li>new offices or online services may change footfall patterns</li>
</ul>
</li>
</ol>

</section>
</section><section>
<h2 id="how-are-machine-learning-workflows-typically-performed">How are Machine Learning workflows typically performed?</h2>

<div class="container w-100 m-0 p-0">
    <div class="row "><div class="col "><p><img src="example-jupyter-notebook.png" alt=""></p>
</div>
<div class="col "><h3 id="via-notebooks-eg-jupyter">Via Notebooks (e.g. Jupyter)</h3>
<ul>
<li>
<p>✅ Interleave code, textual description, and visualizations</p>
</li>
<li>
<p>✅ Interactive usage, allowing for real-time feedback and adjustments</p>
</li>
<li>
<p>✅ Uniform &amp; easy interface to workstations</p>
</li>
<li>
<p>✅ Easy to save, restore, and share</p>
</li>
<li>
<p>❌ Incentivises manual activities over automatic ones</p>
</li>
</ul>
</div>
</div>
</div>
</section><section>
<h2 id="pitfalls-of-manual-work-in-notebooks">Pitfalls of manual work in notebooks</h2>
<ul>
<li><strong>Non-reproducibility</strong>: hidden state, out-of-order execution, forgotten seeds</li>
<li><strong>Weak provenance</strong>: params, code version, data slice, and metrics not logged</li>
<li><strong>Human-in-the-loop gating</strong>: “print accuracy → eyeball → tweak → rerun”</li>
<li><strong>Fragile artifacts</strong>: models overwritten, files named <code>final_v3.ipynb</code></li>
<li><strong>Environment drift</strong>: “works on my machine” dependencies and data paths</li>
<li><strong>Collaboration pain</strong>: merge conflicts, opaque diffs, reviewability issues</li>
</ul>
</section><section>
<h2 id="example-why-manual-runs-mislead">Example: why manual runs mislead</h2>
<ul>
<li>Run 1: random split → train → print accuracy = 0.82</li>
<li>Tweak hyperparams → rerun only training cell → accuracy = 0.86</li>
<li>Forgot to fix seed / re-run split → different data, different metric</li>
<li>No record of params, code, data; “best” model cannot be justified</li>
</ul>


<span class="fragment ">
  <h3 id="consequences">Consequences</h3>
<ul>
<li>Incomparable results, irreproducible models</li>
<li>Hard to automate, schedule, or roll back</li>
<li>No trace from model → code → data → metrics</li>
</ul>

</span>

</section><section>
<h2 id="comparison-among-ml-and-ordinary-software-projects">Comparison among ML and ordinary software projects</h2>
<h3 id="analogies">Analogies</h3>
<ul>
<li>Both <strong>produce</strong> <em>software modules</em> in the end</li>
<li>Both involve <strong>iterative processes</strong>, where <em>feedback</em> is used to improve the product</li>
<li>Both are driven by <strong>tests</strong>/evaluations</li>
<li>Both may benefit from <strong>automation</strong>
<ul>
<li>… and may <em>lose efficiency</em> when activities are performed manually</li>
</ul>
</li>
</ul>


<span class="fragment ">
  <h3 id="differences">Differences</h3>
<ul>
<li>ML projects depend on <em>data</em> (which <em>changes</em> over time)</li>
<li>Models need <em>training</em> and <em>retraining</em>, not just coding</li>
<li>Performance may <em>degrade</em> in production (data drift, bias, new environments)</li>
<li>Many <em>different expertises</em> are involved (data engineers, software engineers, domain experts, operations)</li>
</ul>

</span>



<span class="fragment ">
  <blockquote>
<p>No structured process $\implies$ ML projects may fail to move from notebooks to real-world use</p>
</blockquote>

</span>

</section><section>
<h2 id="machine-learning-operations-mlops">Machine Learning Operations (<a href="https://en.wikipedia.org/wiki/MLOps">MLOps</a>)</h2>
<blockquote>
<p>The practice of organizing and <strong>automating</strong> the <em>end-to-end</em> process of building, training, deploying, and maintaining <em>machine-learning models</em></p>
</blockquote>


<span class="fragment ">
  <h3 id="expected-benefits">Expected benefits</h3>
<ul>
<li><strong>Reproducibility</strong> → the same code + same data always gives the same model</li>
<li><strong>Automation</strong> → repetitive steps (training, testing, deployment) are handled by pipelines</li>
<li><strong>Scalability</strong> → easier to scale up the training process to more data, bigger models, or more computing resources</li>
<li><strong>Monitoring &amp; governance</strong> → models are tracked, evaluated, and kept under control</li>
<li><strong>Collaboration</strong> → teams work on shared infrastructure, with clear responsibilities</li>
<li><strong>Versioning</strong> → models, data, and code are versioned and traceable</li>
</ul>

</span>

</section><section>
<h2 id="how-does-mlops-support-ml-practitioners">How does MLOps support ML practitioners</h2>
<p>MLOps adds <em>infrastructure</em> + <em>processes</em> + <em>automation</em> to make each step more reliable:</p>
<ul>
<li><strong>Data</strong> → <em>version control</em> for datasets, metadata, lineage tracking</li>
<li><strong>Training</strong> → <em>automated pipelines</em> that reproduce experiments on demand</li>
<li><strong>Evaluation</strong> → <em>systematic tracking</em> of metrics, logs, and artifacts</li>
<li><strong>Deployment</strong> → continuous integration &amp; delivery (<em>CI/CD</em>) for ML models, often with <em>model registries</em></li>
<li><strong>Monitoring</strong> → <em>automated checks</em> for performance, drift, fairness, anomalies</li>
<li><strong>Collaboration</strong> → <em>shared repositories</em>, environments, and documentation so teams can work together</li>
</ul>
</section><section>
<h2 id="what-may-happen-without-mlops">What may happen <strong>without</strong> MLOps</h2>
<ul>
<li><strong>Data</strong> in <em>ad-hoc spreadsheets</em> or <em>local files</em> (no version control)</li>
<li><strong>Training</strong> in <em>personal notebooks</em> (hard to reproduce later)</li>
<li><strong>Model evaluation</strong> is <em>manual</em> and <em>undocumented</em> (hard to compare results)</li>
<li><strong>Deployment</strong> = <em>copy-paste</em> code or manual sharing of a <em>model file</em></li>
<li><strong>Monitoring</strong> is much harder → <em>models silently degrade</em></li>
<li><strong>Collaboration</strong> = <code>“send me your notebook by email”</code></li>
</ul>


<span class="fragment ">
  <h3 id="consequences">Consequences</h3>
<ul>
<li>❌ Fragile, non-reproducible workflows</li>
<li>❌ Long delays when models need updating</li>
<li>❌ Difficulty scaling beyond a single researcher</li>
<li>❌ Low trust from stakeholders (“why did accuracy drop?”)</li>
</ul>

</span>

</section><section>
<h1 id="what-about-generative-ai-workflows">What about Generative AI workflows?</h1>
</section><section>
<h2 id="what-is-the-goal-of-a-generative-ai-workflow">What is the <em>goal</em> of a Generative AI workflow?</h2>
<p>Engineering <em>prompts</em>, <em>tools</em>, <em>vector stores</em>, and <em>agents</em> to constrain and govern the behavior of <strong>pre-trained</strong> (<em>foundation</em>) models, in order to:</p>
<ul>
<li><strong>generate</strong> contents (text, images, code, etc.) for a specific purpose
<ul>
<li>e.g. bring unstructured data into a particular format</li>
<li>e.g. produce summaries, reports, highlights</li>
</ul>
</li>
<li><strong>interpret</strong> unstructured data and <em>grasp information</em> from it
<ul>
<li>e.g. extract entities, relations, sentiments</li>
<li>e.g. answer questions about a document</li>
</ul>
</li>
<li><strong>automate</strong> data-processing tasks which are <em>hard to code</em> explicitly
<ul>
<li>e.g. the task is ill-defined (<code>write an evaluation paragraph for each student's work</code>)</li>
<li>e.g. the task requires mining information from unstructured data (<code>find the parties involved in this contract</code>)</li>
<li>e.g. the task is complex yet too narrow to allow for general purpose coding (<code>plan a vacation itinerary based on user preferences</code>)</li>
</ul>
</li>
<li><strong>interact</strong> with users via <em>natural language</em>
<ul>
<li>e.g. chatbots, virtual assistants</li>
</ul>
</li>
</ul>
</section><section>
<h2 id="lets-explain-the-nomenclature">Let’s explain the nomenclature</h2>
<ul>
<li>
<p><strong>Pre-trained <u>foundation</u> models</strong> (PFM): large neural-networks trained on massive datasets to learn general skills (e.g. ‘understanding’ and generating text, images, code)</p>
<ul>
<li>e.g. GPT, PaLM, LLaMA, etc.</li>
</ul>
</li>
<li>
<p><strong>Prompts</strong>: carefully <em>crafted textual inputs</em> that guide some PFM to produce <em>desired outputs</em></p>
<ul>
<li>prompt <strong>templates</strong> are prompts with <em>named placeholders</em> to be filled with specific data at runtime
<ul>
<li>e.g. <code>Write a summary of the following article: {article_text}</code></li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Tools</strong>: external <em>software components</em> (e.g. APIs, databases, search engines) that can be <em>invoked</em> by PFMs to perform specific tasks or retrieve information</p>
<ul>
<li>e.g. a calculator API, a weather API, a database query interface</li>
</ul>
</li>
<li>
<p><strong>Vector stores</strong>: specialized databases that store and retrieve <em>high-dimensional vectors</em> (embeddings) for the sake of <em>information retrieval</em> via <em>similarity search</em></p>
<ul>
<li>e.g. to support <em>retrieval-augmented generation</em> (RAG)</li>
</ul>
</li>
<li>
<p><strong>Agents</strong>: software systems that <em>orchestrate</em> the interaction between PFMs and tools, enabling dynamic decision-making and task execution based on the context and user input</p>
<ul>
<li>e.g. a chatbot that uses a PFM for conversation and invokes a weather API when asked about the weather</li>
<li>e.g. an assistant that uses a PFM to understand user requests and a database to fetch relevant information</li>
</ul>
</li>
</ul>
</section><section>
<h2 id="what-are-the-outcomes-of-a-generative-ai-workflow">What are the <em>outcomes</em> of a Generative AI workflow?</h2>
<ol start="0">
<li>
<p>FM are commonly <u>not</u> produced in-house, but rather <em>accessed</em> via APIs… yet the choice of <strong>what model(s) to use</strong> is crucial</p>
<ul>
<li>must be available, configured, and most commonly imply <em>costs</em> (per call, per token, etc.)</li>
</ul>
</li>
<li>
<p>A set of <strong>prompt templates</strong> (text files, or code snippets) that are known to work well for the tasks at hand</p>
<ul>
<li>commonly assessed via semi-automatic <em>evaluations</em> on a <em>validation set</em> of inputs</li>
</ul>
</li>
<li>
<p>A set of <strong>tool servers</strong> implementing the <a href="https://modelcontextprotocol.io/docs/getting-started/intro">MCP protocol</a> so that tools can be <em>invoked</em> by PFMs</p>
<ul>
<li>these are <em>software modules</em>, somewhat similar to ordinary Web services, offering one endpoint per tool</li>
</ul>
</li>
<li>
<p>A set of <strong>agents</strong>, implementing the logic to orchestrate the interaction between PFMs and tools</p>
<ul>
<li>these are <em>software modules</em>, commonly implemented via libraries such as <a href="https://python.langchain.com/en/latest/index.html">LangChain</a> or <a href="https://gpt-index.readthedocs.io/en/latest/">LlamaIndex</a></li>
</ul>
</li>
<li>
<p>A set of <strong>vector stores</strong> (if needed), populated with relevant data, and accessible by the agents</p>
<ul>
<li>there are <em>software modules</em>, somewhat similar to ordinary DBMS, offering CRUD operations on data chunks <em>indexed by</em> their <em>embeddings</em></li>
</ul>
</li>
</ol>
</section><section>


<section data-shortcode-section="">
<h2 id="what-are-the-phases-of-a-genai-workflow">What are the <em>phases</em> of a GenAI workflow?</h2>
<p>(Similar to the ML workflow in the sense that the goal is to process data, but different in many details e.g. <em>no training</em> is involved)</p>
<p><img src="./genai-workflow.png" alt=""></p>
<ul>
<li>there could be <strong>many iterations</strong> (e.g. for PFM selection, and prompt tuning)</li>
<li>the whole workflow may be <strong>re-started</strong> upon <em>data changes</em>, or <em>task changes</em>, or new <em>PFM availability</em></li>
<li>the <strong>interplay</strong> between prompts, models, tasks, and data may need to be <em>monitored</em> and <em>adjusted</em> continuously</li>
<li>the <strong>data-flow</strong> between components (agents, PFM, tools, vector stores) may need to be <em>tracked</em> for the sake of <em>debugging</em> and <em>monitoring</em></li>
</ul>
</section><section>
<h2 id="peculiar-activities-in-a-typical-genai-workflow">Peculiar activities in a typical GenAI workflow</h2>
<ol>
<li>
<p><strong>Foundation model selection</strong>: choose the most suitable pre-trained model(s) based on task requirements, performance, cost, data protection, and availability</p>
<ul>
<li>implies trying out prompts (even manually) on different models</li>
</ul>
</li>
<li>
<p><strong>Prompt engineering</strong>: design, test, and refine prompt templates to elicit the desired responses</p>
<ul>
<li>implies engineering variables, lengths, formats, contents, etc</li>
</ul>
</li>
<li>
<p><strong>Evaluations</strong>: establish assertions and metrics to assess PFM responses to prompts (attained by instantiating templates over actual data)</p>
<ul>
<li>somewhat similar to <em>unit tests</em> in ordinary software</li>
<li>important when automatic, as they allow quick evaluations on prompt/model combinations</li>
</ul>
</li>
<li>
<p><strong>Tracking</strong> the <em>data-flow</em> between components (agents, PFM, tools, vector stores) to monitor <em>costs</em>, <em>latency</em>, and to <em>debug</em> unexpected behaviors</p>
<ul>
<li>also useful for the sake of <em>auditing</em> and <em>governance</em></li>
</ul>
</li>
</ol>
</section><section>
<h2 id="example-of-genai-workflow-pt-1">Example of GenAI workflow (pt. 1)</h2>
<blockquote>
<p>Support public officers in managing tenders through a GenAI assistant that understands and compares procurement decisions transparently.</p>
</blockquote>
<ol>
<li>
<p><strong>Problem Framing</strong>:</p>
<ul>
<li><em>Content Generation</em>: draft and justify <em>comparisons</em> among suppliers’ offers vs. technical specs</li>
<li><em>Interpretation</em>: understand regulatory documents and technical language</li>
<li><em>Automation</em>: retrieve relevant laws, norms, and prior tender examples</li>
<li><em>Interaction</em>: enable officers to query and validate results through natural language</li>
</ul>
</li>
<li>
<p><strong>Data Collection</strong>: past tenders’ technical specifications, acts, etc; regulatory documents, etc.</p>
</li>
<li>
<p><strong>Data Preparation</strong>:</p>
<ul>
<li>devise useful data schema &amp; extract relevant data from documents</li>
<li>anonymize sensitive info (suppliers, personal data)</li>
<li>segment documents and index by topic (law, SLA, price table, etc.)</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="example-of-genai-workflow-pt-2">Example of GenAI workflow (pt. 2)</h2>
<ol start="4">
<li>
<p><strong>Prompt Engineering</strong>:</p>
<ol>
<li>design prompt templates for comparison, justification, and Q&amp;A
<ul>
<li>use role-based system prompts (<code>You are a procurement evaluator…</code>)</li>
</ul>
</li>
<li>allocate placeholders for RAG-retrieved data chunks</li>
<li>iterate on template design based on manual tests</li>
</ol>
</li>
<li>
<p><strong>Foundation Model Selection</strong>: multi-lingual? specialized in legal/technical text? cost constraints? support for tools?</p>
</li>
<li>
<p><strong>Vector stores</strong>: storing embeddings for tender documents &amp; specs, legal texts &amp; guidelines, previous evaluation, templates</p>
<ol>
<li>choose embedding model, chunking strategy, and populate vector store</li>
<li>engineer retrieval strategies to fetch relevant chunks</li>
</ol>
</li>
<li>
<p><strong>Tools</strong>:</p>
<ul>
<li>regulation lookup API + tender database query API</li>
<li>report generation out of document templates</li>
<li>automate scoring calculations via spreadsheet or Python scripts generation</li>
</ul>
</li>
<li>
<p><strong>Agents</strong>:</p>
<ol>
<li>exploit LLM to extract structured check-lists out of technical specs</li>
<li>orchestrate RAG, tool invocations, and prompt templates to score each offer</li>
<li>generate comparison reports</li>
<li>…</li>
</ol>
</li>
</ol>

</section>
</section><section>
<h2 id="llm-operations-llmops">LLM Operations (<a href="https://www.databricks.com/it/glossary/llmops">LLMOps</a>)</h2>
<blockquote>
<p>The practice of organizing and <strong>automating</strong> the <em>end-to-end</em> process of building, evaluating, deploying, and maintaining <em>GenAI applications</em></p>
</blockquote>
<br>


<span class="fragment ">
  <h4 id="in-a-nutshell-mlops-for-genai">In a nutshell: <strong>MLOps for GenAI</strong></h4>

</span>

<br>


<span class="fragment ">
  <h3 id="expected-benefits">Expected benefits</h3>
<ul>
<li><strong>Systematicity</strong> → structured processes to manage prompts, tools, and agents</li>
<li><strong>Efficiency</strong> → reuse of components, templates, and evaluations</li>
<li><strong>Scalability</strong> → easier to test, and update individual components (prompt templates, tools, agents)</li>
<li><strong>Monitoring &amp; governance</strong> → components are tracked, evaluated, and kept under control</li>
</ul>

</span>

</section><section>
<h2 id="how-does-llmops-support-genai-practitioners">How does LLMOps support GenAI practitioners</h2>
<p>LLMOps adds <em>infrastructure</em> + <em>processes</em> + <em>automation</em> to make each step more reliable:</p>
<ul>
<li><strong>Foundation models</strong> → <em>catalogs</em> of available models, with metadata on capabilities, costs, and usage policies</li>
<li><strong>Provider Gateways</strong> → standardized APIs to access different PFM providers (e.g. OpenAI, HuggingFace) uniformly, without code rewrites</li>
<li><strong>Prompt engineering</strong> → <em>version control</em> for prompt templates, systematic testing frameworks</li>
<li><strong>Tool integration</strong> → <em>standardized protocols</em> (e.g. MCP) and libraries to connect tools with PFMs + <em>gateway technologies</em> to aggregate multiple tools</li>
<li><strong>Agents</strong> → <em>provider-agnostic libraries</em> and frameworks (e.g. LangChain) to build, manage, and orchestrate agents</li>
<li><strong>Vector stores</strong> → <em>standardized interfaces</em> to store and retrieve data chunks via embeddings, with support for <em>multiple backend</em> DBMS</li>
<li><strong>Evaluation &amp; monitoring</strong> → <em>automated</em> frameworks to run <em>evaluations</em>, <em>track performance</em>, and <em>monitor costs</em></li>
</ul>
</section><section>
<h2 id="what-may-happen-without-llmops">What may happen <strong>without</strong> LLMOps</h2>
<ul>
<li>
<p><strong>Foundation models</strong> are <em>hard-coded</em> in the application</p>
<ul>
<li>making it difficult to switch providers or models</li>
</ul>
</li>
<li>
<p><strong>Prompt templates</strong> are <em>scattered</em> in code or documents</p>
<ul>
<li>making it hard to track changes or reuse them</li>
</ul>
</li>
<li>
<p><strong>Tools</strong> are <em>manually integrated</em>, leading to:</p>
<ul>
<li>brittle connections,</li>
<li>lack of observability,</li>
<li>maintenance challenges</li>
</ul>
</li>
<li>
<p><strong>Agents</strong> are <em>ad-hoc scripts</em> that mix logic, PFM calls, and tool invocations</p>
<ul>
<li>making them hard to debug, extend or compose</li>
</ul>
</li>
<li>
<p><strong>Vector stores</strong> are <em>tightly coupled</em> with specific DBMS</p>
<ul>
<li>making it hard to migrate or scale</li>
</ul>
</li>
<li>
<p><strong>Evaluation &amp; monitoring</strong> are <em>manual</em> and <em>sporadic</em> leading to undetected issues, cost overruns, and loss of trust</p>
</li>
</ul>
</section><section>
<h1 id="mlops-and-llmops-with-mlflow">MLOps and LLMOps with <a href="https://mlflow.org/">MLflow</a></h1>
</section><section>
<h2 id="what-is-mlflow">What is MLflow? <a href="https://mlflow.org/">https://mlflow.org/</a></h2>
<p><img src="./mlflow-logo.webp" alt=""></p>
<blockquote>
<p>An <em>open-source</em> Python framework for <strong>MLOps</strong> and (most recently) <strong>LLMOps</strong></p>
</blockquote>
<ul>
<li>usable either in-cloud (e.g. via <a href="https://www.databricks.com/">Databricks</a>) or on-premises (self-hosted)
<ul>
<li>we’ll see the latter setup</li>
</ul>
</li>
</ul>


<span class="fragment ">
  <h3 id="outline">Outline</h3>
<ol>
<li>First, we focus on how to use MLflow for the sake of <em>MLOps</em></li>
<li>Then, we show how MLflow can be used for <em>LLMOps</em> as well</li>
</ol>

</span>

</section><section>
<h2 id="mlflow-for-mlops-main-components-pt-1">MLflow for MLOps: main components pt. 1</h2>
<p><img src="./mlflow-components-mlops.png" alt=""></p>

<div class="container w-100 m-0 p-0">
    <div class="row "><div class="col "><h3 id="provides">Provides</h3>
<ul>
<li><em>UI</em> to visualize and monitor experiments</li>
<li>Facilities to <em>evaluate</em> ML models (metrics and charts)</li>
<li>Python API and command-line support for <em>ML operations</em></li>
</ul>
</div>
<div class="col "><h3 id="how">How</h3>
<ul>
<li>by <em>tracking</em> metadata about datasets, experiments, and models</li>
<li>by <em>serializing</em> and <em>storing</em> models, charts, predictions, metrics, etc.</li>
<li>by facilitating <em>deployment</em> of models <em>as services</em></li>
</ul>
</div>
</div>
</div>
</section><section>
<h2 id="mlflow-for-mlops-main-components-pt-2">MLflow for MLOps: main components pt. 2</h2>
<p><img src="./mlflow-components-mlops-2.jpg" alt=""></p>
</section><section>
<h2 id="mlflows-common-set-ups">MLflow’s common set-ups</h2>
<p><img src="mlflow-architecture-mlops.png" alt=""></p>

<div class="container w-100 m-0 p-0">
    <div class="row "><div class="col "><ol>
<li>Solo development (serverless)</li>
</ol>
</div>
<div class="col "><ol start="2">
<li>Solo development (local server + remote store)</li>
</ol>
</div>
<div class="col "><ol start="3">
<li>Team work (remote server)</li>
</ol>
</div>
</div>
</div>
</section><section>
<h2 id="mlflows-complex-set-up">MLflow’s complex set-up</h2>
<!-- ![](./mlflow-multi-server.png) -->





<img src="./mlflow-multi-server.png" alt="" style="width: 100%; max-width: 95vw; max-height: 50vh; object-fit: contain;">

<p>Notice that, in set-up 3, there could be up to <em>three servers</em> involved:</p>
<ol>
<li>the <strong>Backend Store</strong> server (a relational DBMS, e.g. PostgreSQL, MySQL, SQLite, etc.) to store <em>metadata</em></li>
<li>the <strong>Artifact Store</strong> server (e.g. S3, Azure Blob Storage, etc.) to store <em>artifacts</em> via some file-system interface</li>
<li>the <strong>MLflow Tracking Server</strong> to provide the UI and API endpoints
<ul>
<li>this is mediating the interaction between users and the two stores</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="mlflows-functioning-overview">MLflow’s functioning overview</h2>
<h3 id="assumptions">Assumptions</h3>
<ol>
<li>Some Python code is in place to perform ML tasks (via common libraries such as <code>scikit-learn</code>, <code>TensorFlow</code>, <code>PyTorch</code>, etc.)</li>
<li>The code is using MLflow’s Python API to log metadata about experiments, datasets, models, metrics, etc.</li>
</ol>


<span class="fragment ">
  <h3 id="workflow">Workflow</h3>
<ol start="0">
<li>
<p>Start the Python code</p>
</li>
<li>
<p>MLflow’s Python API invoked in the code will actually log all relevant <em>metadata</em> and <em>artifacts</em> as the code runs</p>
<ul>
<li><strong>metadata</strong> $\approx$ experiment id, run id, timings, data schemas, input parameters, hyper-parameters, metric values, etc.</li>
<li><strong>artifact</strong> $\approx$ dataset, model, chart, etc.</li>
</ul>
</li>
<li>
<p>Metadata and artifacts may be stored (depending on the configuration):</p>
<ul>
<li>on the local file system</li>
<li>on a remote backend and artifact store</li>
</ul>
</li>
</ol>

</span>

</section><section>
<h2 id="mlflow-usage-remarks">MLflow usage remarks</h2>
<ul>
<li>
<p><strong>Assumption 2</strong> may require additional effort from the developer(s)</p>
<ul>
<li>this is kept minimal via <a href="https://mlflow.org/docs/3.3.1/ml/tracking/autolog/">auto-logging</a> available for most common ML libraries</li>
</ul>
</li>
<li>
<p><strong>No big constraint</strong> on how to organize the Python code it-self…</p>
</li>
<li>
<p>… but many <strong>benefits</strong> (<em>automation</em>, reproducibility) may come from organizing the code as an <a href="https://mlflow.org/docs/latest/ml/projects/">MLflow Project</a></p>
<ul>
<li>$\implies$ <em>decomposing</em> the <em>code</em> into multiple scripts</li>
<li>$\implies$ thinking about the <em>parametric aspects</em> of the experiment, and account for <em>command-line arguments</em> accordingly</li>
<li>$\implies$ thinking about the <em>environment</em> where the code will run (e.g. dependencies, libraries, etc.)</li>
<li>we’ll see this aspect later</li>
</ul>
</li>
</ul>
</section><section>


<section data-shortcode-section="">
<h2 id="a-taste-of-mlflows-tracking-api-pt-1">A taste of MLflow’s Tracking API (pt. 1)</h2>
<ol>
<li>
<p>Install MLflow into your Python environment</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>pip install mlflow
</span></span></code></pre></div></li>
<li>
<p>Consider the following dummy script:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">import</span> <span style="color:#000">sys</span> <span style="color:#8f5902;font-style:italic"># to read command-line arguments</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">import</span> <span style="color:#000">tempfile</span> <span style="color:#8f5902;font-style:italic"># to save generated files into temporary directories</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">import</span> <span style="color:#000">mlflow</span> <span style="color:#8f5902;font-style:italic"># to use MLflow functionalities</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">from</span> <span style="color:#000">random</span> <span style="color:#204a87;font-weight:bold">import</span> <span style="color:#000">Random</span> <span style="color:#8f5902;font-style:italic"># to generate random numbers with controlled seed</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Set the experiment name (creates it if it does not exist)</span>
</span></span><span style="display:flex;"><span><span style="color:#000">mlflow</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">set_experiment</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">experiment_name</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"logging_example"</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Read a seed from command-line arguments (default: 42)</span>
</span></span><span style="display:flex;"><span><span style="color:#000">seed</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#204a87">int</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">sys</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">argv</span><span style="color:#000;font-weight:bold">[</span><span style="color:#0000cf;font-weight:bold">1</span><span style="color:#000;font-weight:bold">])</span> <span style="color:#204a87;font-weight:bold">if</span> <span style="color:#204a87">len</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">sys</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">argv</span><span style="color:#000;font-weight:bold">)</span> <span style="color:#ce5c00;font-weight:bold">&gt;</span> <span style="color:#0000cf;font-weight:bold">1</span> <span style="color:#204a87;font-weight:bold">else</span> <span style="color:#0000cf;font-weight:bold">42</span>
</span></span><span style="display:flex;"><span><span style="color:#000">rand</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#000">Random</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">seed</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Start an MLflow run, naming it "example_run" (otherwise random name is generated)</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">with</span> <span style="color:#000">mlflow</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">start_run</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">run_name</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"example_run"</span><span style="color:#000;font-weight:bold">)</span> <span style="color:#204a87;font-weight:bold">as</span> <span style="color:#000">run</span><span style="color:#000;font-weight:bold">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8f5902;font-style:italic"># notice that experiments are runs are identified by their numeric IDs</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87">print</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">f</span><span style="color:#4e9a06">"Started MLflow run with ID: </span><span style="color:#4e9a06">{</span><span style="color:#000">run</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">info</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">run_id</span><span style="color:#4e9a06">}</span><span style="color:#4e9a06"> in experiment ID: </span><span style="color:#4e9a06">{</span><span style="color:#000">run</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">info</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">experiment_id</span><span style="color:#4e9a06">}</span><span style="color:#4e9a06">"</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8f5902;font-style:italic"># Log a parameter "seed" with the given seed value</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">mlflow</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">log_param</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"seed"</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">seed</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8f5902;font-style:italic"># Let's simulate 5 different metric scores to be logged</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">for</span> <span style="color:#000">i</span> <span style="color:#204a87;font-weight:bold">in</span> <span style="color:#204a87">range</span><span style="color:#000;font-weight:bold">(</span><span style="color:#0000cf;font-weight:bold">5</span><span style="color:#000;font-weight:bold">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#000">mlflow</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">log_metric</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">f</span><span style="color:#4e9a06">"random_</span><span style="color:#4e9a06">{</span><span style="color:#000">i</span><span style="color:#4e9a06">}</span><span style="color:#4e9a06">"</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">rand</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">random</span><span style="color:#000;font-weight:bold">())</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">mlflow</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">log_metric</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"random_4"</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">rand</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">randint</span><span style="color:#000;font-weight:bold">(</span><span style="color:#0000cf;font-weight:bold">1</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#0000cf;font-weight:bold">10</span><span style="color:#000;font-weight:bold">))</span> <span style="color:#8f5902;font-style:italic"># overwrite last metric</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8f5902;font-style:italic"># Create and log an example artifact (a text file, generated inside temporaty directory)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">with</span> <span style="color:#000">tempfile</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">TemporaryDirectory</span><span style="color:#000;font-weight:bold">()</span> <span style="color:#204a87;font-weight:bold">as</span> <span style="color:#000">tmpdir</span><span style="color:#000;font-weight:bold">:</span>
</span></span><span style="display:flex;"><span>        <span style="color:#000">file_path</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#4e9a06">f</span><span style="color:#4e9a06">"</span><span style="color:#4e9a06">{</span><span style="color:#000">tmpdir</span><span style="color:#4e9a06">}</span><span style="color:#4e9a06">/example.txt"</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">with</span> <span style="color:#204a87">open</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">file_path</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#4e9a06">"w"</span><span style="color:#000;font-weight:bold">)</span> <span style="color:#204a87;font-weight:bold">as</span> <span style="color:#000">f</span><span style="color:#000;font-weight:bold">:</span>
</span></span><span style="display:flex;"><span>            <span style="color:#000">f</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">write</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"This is an example artifact."</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#000">mlflow</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">log_artifact</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">file_path</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">artifact_path</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"examples"</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8f5902;font-style:italic">#&nbsp;Simulate an error in the run if the seed parameter is odd</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">if</span> <span style="color:#000">seed</span> <span style="color:#ce5c00;font-weight:bold">%</span> <span style="color:#0000cf;font-weight:bold">2</span> <span style="color:#ce5c00;font-weight:bold">==</span> <span style="color:#0000cf;font-weight:bold">1</span><span style="color:#000;font-weight:bold">:</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">raise</span> <span style="color:#c00;font-weight:bold">ValueError</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"Let the run fail for odd seeds!"</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87">print</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"Run completed successfully."</span><span style="color:#000;font-weight:bold">)</span>
</span></span></code></pre></div></li>
</ol>
</section><section>
<h2 id="a-taste-of-mlflows-tracking-api-pt-2">A taste of MLflow’s Tracking API (pt. 2)</h2>
<ol start="3">
<li>
<p>Let’s run the experiment <em>twice</em>, with <strong>different seeds</strong>:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>python logging_example.py <span style="color:#0000cf;font-weight:bold">42</span>
</span></span><span style="display:flex;"><span>python logging_example.py <span style="color:#0000cf;font-weight:bold">43</span>
</span></span></code></pre></div></li>
<li>
<p>The <strong>1st</strong> <em>successful</em> run shall output something like:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>2025/11/10 11:44:49 INFO mlflow.tracking.fluent: Experiment with name 'logging_example' does not exist. Creating a new experiment.
</span></span><span style="display:flex;"><span>Started MLflow run with ID: 378f18735f6d4abd8abeba76f4029bea in experiment ID: 931233098002846893
</span></span></code></pre></div></li>
<li>
<p>The <strong>2nd</strong> <em>failing</em> run shall output something like:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>Started MLflow run with ID: 9b52b7b7416e423ca9c878fba9b5c667 in experiment ID: 931233098002846893
</span></span><span style="display:flex;"><span>Traceback (most recent call last):
</span></span><span style="display:flex;"><span>File "/home/gciatto/Work/Code/example-mlops/mlflow_tracking.py", line 28, in &lt;module&gt;
</span></span><span style="display:flex;"><span>    raise ValueError("Let the run fail for odd seeds!")
</span></span><span style="display:flex;"><span>ValueError: Let the run fail for odd seeds!
</span></span></code></pre></div></li>
<li>
<p>Look at your file system, notice that a new <code>mlruns/</code> folder has appeared next to Python script:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>mlruns
</span></span><span style="display:flex;"><span>├── 931233098002846893
</span></span><span style="display:flex;"><span>│   ├── 378f18735f6d4abd8abeba76f4029bea
</span></span><span style="display:flex;"><span>│   │   ├── artifacts
</span></span><span style="display:flex;"><span>│   │   │   └── examples
</span></span><span style="display:flex;"><span>│   │   │       └── example.txt
</span></span><span style="display:flex;"><span>│   │   ├── meta.yaml
</span></span><span style="display:flex;"><span>│   │   ├── metrics
</span></span><span style="display:flex;"><span>│   │   │   ├── random_0
</span></span><span style="display:flex;"><span>│   │   │   ├── random_1
</span></span><span style="display:flex;"><span>│   │   │   ├── random_2
</span></span><span style="display:flex;"><span>│   │   │   ├── random_3
</span></span><span style="display:flex;"><span>│   │   │   └── random_4
</span></span><span style="display:flex;"><span>│   │   ├── params
</span></span><span style="display:flex;"><span>│   │   │   └── seed
</span></span><span style="display:flex;"><span>│   │   └── tags
</span></span><span style="display:flex;"><span>│   │       ├── mlflow.runName
</span></span><span style="display:flex;"><span>│   │       ├── mlflow.source.git.commit
</span></span><span style="display:flex;"><span>│   │       ├── mlflow.source.name
</span></span><span style="display:flex;"><span>│   │       ├── mlflow.source.type
</span></span><span style="display:flex;"><span>│   │       └── mlflow.user
</span></span><span style="display:flex;"><span>│   ├── 9b52b7b7416e423ca9c878fba9b5c667
</span></span><span style="display:flex;"><span>│   │   ├── artifacts
</span></span><span style="display:flex;"><span>│   │   │   └── examples
</span></span><span style="display:flex;"><span>│   │   │       └── example.txt
</span></span><span style="display:flex;"><span>│   │   ├── meta.yaml
</span></span><span style="display:flex;"><span>│   │   ├── metrics
</span></span><span style="display:flex;"><span>│   │   │   ├── random_0
</span></span><span style="display:flex;"><span>│   │   │   ├── random_1
</span></span><span style="display:flex;"><span>│   │   │   ├── random_2
</span></span><span style="display:flex;"><span>│   │   │   ├── random_3
</span></span><span style="display:flex;"><span>│   │   │   └── random_4
</span></span><span style="display:flex;"><span>│   │   ├── params
</span></span><span style="display:flex;"><span>│   │   │   └── seed
</span></span><span style="display:flex;"><span>│   │   └── tags
</span></span><span style="display:flex;"><span>│   │       ├── mlflow.runName
</span></span><span style="display:flex;"><span>│   │       ├── mlflow.source.git.commit
</span></span><span style="display:flex;"><span>│   │       ├── mlflow.source.name
</span></span><span style="display:flex;"><span>│   │       ├── mlflow.source.type
</span></span><span style="display:flex;"><span>│   │       └── mlflow.user
</span></span><span style="display:flex;"><span>│   ├── meta.yaml
</span></span><span style="display:flex;"><span>│   └── tags
</span></span><span style="display:flex;"><span>│       └── mlflow.experimentKind
</span></span><span style="display:flex;"><span>└── models
</span></span></code></pre></div></li>
</ol>
</section><section>
<h2 id="a-taste-of-mlflows-tracking-api-pt-3">A taste of MLflow’s Tracking API (pt. 3)</h2>
<ol start="7">
<li>
<p>Let’s now start the <strong>MLflow Web UI</strong> via the following command, to <em>visualize</em> the experiment runs:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>mlflow ui
</span></span></code></pre></div><p>then browse to <a href="http://127.0.0.1:5000">http://127.0.0.1:5000</a> in your favorite browser</p>
</li>
<li>
<p>You should see something like the following:
<img src="./mlflow-ui-dummy-1.png" alt=""></p>
</li>
</ol>
</section><section>
<h2 id="a-taste-of-mlflows-tracking-api-pt-4">A taste of MLflow’s Tracking API (pt. 4)</h2>
<ol start="9">
<li>Click on the <strong>experiment name</strong> (<code>logging_example</code>) to see the two runs:
<img src="./mlflow-ui-dummy-2.png" alt="">
<ul>
<li>notice that the <em>latest</em> run is marked as <strong>failing</strong> while the earliest one is successful
<ul>
<li>the <strong>exit code</strong> of the run is registered automatically</li>
</ul>
</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="a-taste-of-mlflows-tracking-api-pt-5">A taste of MLflow’s Tracking API (pt. 5)</h2>
<ol start="10">
<li>You may switch to the <strong>“Chart view”</strong> to see a <em>comparison</em> among the logged <em>metrics</em> (across all runs):
<img src="./mlflow-ui-dummy-2a.png" alt=""></li>
</ol>
</section><section>
<h2 id="a-taste-of-mlflows-tracking-api-pt-6">A taste of MLflow’s Tracking API (pt. 6)</h2>
<ol start="11">
<li>You may click on one <strong>run name</strong> to see details about that run
<img src="./mlflow-ui-dummy-3.png" alt="">
<ul>
<li>notice the logged <em>parameters</em>, <em>metrics</em>, and <em>metadata</em>
<ul>
<li>notice that these are the same information we logged via the MLflow Python API + some automatically-inferred metadata</li>
</ul>
</li>
<li>notice that these data are the same one stored on the file system, in <code>mlruns/</code></li>
</ul>
</li>
</ol>
</section><section>
<h2 id="a-taste-of-mlflows-tracking-api-pt-7">A taste of MLflow’s Tracking API (pt. 7)</h2>
<ol start="12">
<li>You may switch to the <strong>“Modal metrics”</strong> tab to see the logged metrics in graphical form:
<img src="./mlflow-ui-dummy-4.png" alt=""></li>
</ol>
</section><section>
<h2 id="a-taste-of-mlflows-tracking-api-pt-8">A taste of MLflow’s Tracking API (pt. 8)</h2>
<ol start="13">
<li>You may switch to the <strong>“Artifacts”</strong> tab to see the logged artifacts:
<img src="./mlflow-ui-dummy-5.png" alt="">
<ul>
<li>notice that the <code>example.txt</code> artifact is inside some “virtual” <code>examples/</code> folder
<ul>
<li>as we asked explicitly in the Python code</li>
</ul>
</li>
</ul>
</li>
</ol>

</section>
</section><section>


<section data-shortcode-section="">
<h2 id="autologging-apis-pt-1">Autologging APIs (pt. 1)</h2>
<ol>
<li>Consider the following script, aimed at training a <a href="https://scikit-learn.org/stable/modules/tree.html">decision tree classifier</a> for the <a href="https://it.wikipedia.org/wiki/Dataset_Iris">Iris dataset</a>, via <a href="https://scikit-learn.org">SciKit-Learn library</a>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">from</span> <span style="color:#000">sklearn.datasets</span> <span style="color:#204a87;font-weight:bold">import</span> <span style="color:#000">load_iris</span> <span style="color:#8f5902;font-style:italic"># to load the iris dataset</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">from</span> <span style="color:#000">sklearn.tree</span> <span style="color:#204a87;font-weight:bold">import</span> <span style="color:#000">DecisionTreeClassifier</span> <span style="color:#8f5902;font-style:italic"># to use decision tree classifier</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">import</span> <span style="color:#000">mlflow</span> <span style="color:#8f5902;font-style:italic"># to use MLflow functionalities</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">import</span> <span style="color:#000">sys</span> <span style="color:#8f5902;font-style:italic"># to read command-line arguments</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Set the experiment name (creates it if it does not exist)</span>
</span></span><span style="display:flex;"><span><span style="color:#000">mlflow</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">set_experiment</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"autologging-example"</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Enable autologging for scikit-learn (and other ML libraries in general)</span>
</span></span><span style="display:flex;"><span><span style="color:#000">mlflow</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">autolog</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">log_datasets</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87;font-weight:bold">True</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">log_models</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87;font-weight:bold">True</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">log_model_signatures</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87;font-weight:bold">True</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">log_input_examples</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87;font-weight:bold">True</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Read a seed from command-line arguments (default: 42)</span>
</span></span><span style="display:flex;"><span><span style="color:#000">seed</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#204a87">int</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">sys</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">argv</span><span style="color:#000;font-weight:bold">[</span><span style="color:#0000cf;font-weight:bold">1</span><span style="color:#000;font-weight:bold">])</span> <span style="color:#204a87;font-weight:bold">if</span> <span style="color:#204a87">len</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">sys</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">argv</span><span style="color:#000;font-weight:bold">)</span> <span style="color:#ce5c00;font-weight:bold">&gt;</span> <span style="color:#0000cf;font-weight:bold">1</span> <span style="color:#204a87;font-weight:bold">else</span> <span style="color:#0000cf;font-weight:bold">42</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Start an MLflow run, naming it "autologging_run"</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">with</span> <span style="color:#000">mlflow</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">start_run</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">run_name</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"autologging_run"</span><span style="color:#000;font-weight:bold">):</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8f5902;font-style:italic"># Load full iris dataset</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">X</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">y</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#000">load_iris</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">return_X_y</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87;font-weight:bold">True</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8f5902;font-style:italic"># Train model on the entire dataset (using the given seed)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">model</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#000">DecisionTreeClassifier</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">random_state</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#000">seed</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">model</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">fit</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">X</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">y</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8f5902;font-style:italic"># Evaluate model on the entire dataset (training accuracy)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">training_score</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#000">model</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">score</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">X</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">y</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87">print</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"Training accuracy:"</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">training_score</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8f5902;font-style:italic"># Raise an error if training accuracy is below 90%</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">if</span> <span style="color:#000">training_score</span> <span style="color:#ce5c00;font-weight:bold">&lt;</span> <span style="color:#0000cf;font-weight:bold">0.9</span><span style="color:#000;font-weight:bold">:</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">raise</span> <span style="color:#c00;font-weight:bold">ValueError</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"Training accuracy is too low: "</span> <span style="color:#ce5c00;font-weight:bold">+</span> <span style="color:#204a87">str</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">training_score</span><span style="color:#000;font-weight:bold">))</span>
</span></span></code></pre></div></li>
</ol>
</section><section>
<h2 id="autologging-apis-pt-2">Autologging APIs (pt. 2)</h2>
<ol>
<li>
<p>Let’s run the experiment <em>once</em>, with default seed:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>python autologging_example.py
</span></span></code></pre></div></li>
<li>
<p>The run shall output something like:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>2025/11/11 16:27:49 INFO mlflow.tracking.fluent: Experiment with name 'autologging-example' does not exist. Creating a new experiment.
</span></span><span style="display:flex;"><span>2025/11/11 16:27:50 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.
</span></span><span style="display:flex;"><span>Training accuracy: 1.0
</span></span></code></pre></div></li>
<li>
<p>Let’s now look at the MLflow UI again (via <code>mlflow ui</code> command) to see the new experiment:
<img src="./mlflow-ui-autolog-1.png" alt=""></p>
</li>
</ol>
</section><section>
<h2 id="autologging-apis-pt-3">Autologging APIs (pt. 3)</h2>
<ol start="4">
<li>Click on the <strong>experiment name</strong> (<code>autologging-example</code>) to see the run:
<img src="./mlflow-ui-autolog-2.png" alt="">
<ul>
<li>notice that the run logged many more information automatically (e.g. dataset, model, etc.)</li>
<li>notice that the <em>green tick</em> indicates that the run was successful <strong>(training score is above 90%)</strong></li>
</ul>
</li>
</ol>
</section><section>
<h2 id="autologging-apis-pt-4">Autologging APIs (pt. 4)</h2>
<ol start="5">
<li>
<p>Click on the <strong>run name</strong> to see details about that run</p>
 <img src="./mlflow-ui-autolog-3a.png" alt="" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain;">
 <!-- ![](./mlflow-ui-autolog-3a.png) -->
<ul>
<li>notice the logged <em>parameters</em>, <em>metrics</em>, and <em>metadata</em>
<ul>
<li><strong>recall that we didin’t log any of these explicitly</strong> in the Python code!</li>
</ul>
</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="autologging-apis-pt-4-1">Autologging APIs (pt. 4)</h2>
<ol start="5">
<li>
<p>Click on the <strong>run name</strong> to see details about that run</p>
 <img src="./mlflow-ui-autolog-3b.png" alt="" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain;">
 <!-- ![](./mlflow-ui-autolog-3b.png) -->
<ul>
<li>notice the logged <em>model</em>
<ul>
<li><strong>recall that we didin’t log it explicitly</strong> in the Python code!</li>
</ul>
</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="autologging-apis-pt-5">Autologging APIs (pt. 5)</h2>
<ol start="6">
<li>Click on the <strong>“Artifacts”</strong> tab to see the automatically-logged artifacts:
<img src="./mlflow-ui-autolog-4.png" alt="">
<ul>
<li>notice the file <code>estimator.html</code> (HTML representation of the SciKit-Learn processing pipeline)</li>
<li>notice the file <code>metric_info.json</code> (details about automatically-logged metrics)</li>
<li>notice the file <code>training_confusion_matrix.png</code> (confusion matrix <em>picture</em> on training data)</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="autologging-apis-pt-6">Autologging APIs (pt. 6)</h2>
<ol start="7">
<li>
<p>Click on the logged <strong>model</strong> to see its details:</p>
 <img src="./mlflow-ui-autolog-5.png" alt="" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain;">
 <!-- ![](./mlflow-ui-autolog-5.png) -->
<ul>
<li>notice that some <em>metrics</em> are automatically computed on training data (accuracy, f1-score, precision, AUC ROC, etc.)</li>
<li>notice the logged <em>parameters</em> (these are the actual parameters of the SciKit-Learn class)</li>
<li>notice that the <em>training dataset</em> schema is logged as well (this is the <strong>input schema</strong> expected by the model)</li>
<li>notice the <em>ID of the model</em>: <code>m-cbc72d11f1e6405bbaa77889f08b92dd</code>
<ul>
<li>meaning that the URI of the model will be <a href="mlflow://m-cbc72d11f1e6405bbaa77889f08b92dd">mlflow://m-cbc72d11f1e6405bbaa77889f08b92dd</a></li>
</ul>
</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="autologging-apis-pt-7">Autologging APIs (pt. 7)</h2>
<ol start="8">
<li>Click on the <strong>“Artifacts”</strong> tab of the model view to see automatically-logged artifacts for the model:
<img src="./mlflow-ui-autolog-6.png" alt="">
<ul>
<li>notice file <code>MLmodel</code> (YAML description of the model)</li>
<li>notice file <code>model.pkl</code> (the actual serialized model, in Python <code>pickle</code> format)</li>
<li>notice file <code>requirements.txt</code> (Python environment to run the model, in <code>pip</code> format)</li>
<li>notice file <code>serving_input_example.json</code> (example input data for model serving via MLflow)</li>
</ul>
</li>
</ol>

</section>
</section><section>
<h2 id="model-deployment-and-serving-via-mlflow">Model deployment and serving via MLflow</h2>
<!-- ![](./mlflow-serving.png) -->





<img src="./mlflow-serving.png" alt="" style="width: 100%; max-width: 95vw; max-height: 40vh; object-fit: contain;">

<ul>
<li>
<p>MLflow assists in <strong>model deployment</strong> by <em>mediating the interaction</em> between logged models and their clients</p>
<ul>
<li>clients are assumed to use the models in <em>inference</em> mode (i.e. for prediction serving)</li>
<li>clients may be either <strong>command-line tools</strong> or <strong>Web API</strong> consumers</li>
</ul>
</li>
<li>
<p>MLflow automates the creation of <strong>container images</strong> for the sake of model deployment</p>
<ul>
<li>these images may be deployed on common <em>cloud platforms</em> (e.g. AWS SageMaker, Azure ML, Google Cloud AI Platform, etc.)</li>
<li>these images may be deployed <em>on-premises</em> as well (e.g. via Docker or Kubernetes)</li>
</ul>
</li>
</ul>
</section><section>


<section data-shortcode-section="">
<h2 id="model-serving-via-mlflow-pt-1">Model serving via MLflow (pt. 1)</h2>
<blockquote>
<p>Saved models can be easily used via MLflow’s <strong>command-line interface</strong> (CLI) or <strong>Web API</strong> for prediction serving</p>
</blockquote>
<h3 id="cli-example">CLI Example</h3>
<ol>
<li>
<p>Download the file <code>serving_input_example.json</code> locally</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#000;font-weight:bold">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">"inputs"</span><span style="color:#000;font-weight:bold">:</span> <span style="color:#000;font-weight:bold">[</span>
</span></span><span style="display:flex;"><span>        <span style="color:#000;font-weight:bold">[</span><span style="color:#0000cf;font-weight:bold">5.1</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#0000cf;font-weight:bold">3.5</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#0000cf;font-weight:bold">1.4</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#0000cf;font-weight:bold">0.2</span><span style="color:#000;font-weight:bold">],</span>
</span></span><span style="display:flex;"><span>        <span style="color:#000;font-weight:bold">[</span><span style="color:#0000cf;font-weight:bold">7.0</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#0000cf;font-weight:bold">3.2</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#0000cf;font-weight:bold">4.7</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#0000cf;font-weight:bold">1.4</span><span style="color:#000;font-weight:bold">],</span>
</span></span><span style="display:flex;"><span>        <span style="color:#000;font-weight:bold">[</span><span style="color:#0000cf;font-weight:bold">6.3</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#0000cf;font-weight:bold">3.3</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#0000cf;font-weight:bold">6.0</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#0000cf;font-weight:bold">2.5</span><span style="color:#000;font-weight:bold">]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000;font-weight:bold">]</span>
</span></span><span style="display:flex;"><span><span style="color:#000;font-weight:bold">}</span>
</span></span></code></pre></div></li>
<li>
<p>Run</p>
<pre tabindex="0"><code class="nohighlight" data-noescape="">mlflow models predict --env-manager local -m "models:/m-1abbea58e1cf442ab9412b7eae572523" -i path/to/serving_input_example.json
</code></pre></li>
<li>
<p>Observe the predictions output:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>{"predictions": [0, 1, 2]}
</span></span></code></pre></div></li>
</ol>
</section><section>
<h2 id="model-serving-via-mlflow-pt-2">Model serving via MLflow (pt. 2)</h2>
<blockquote>
<p>Saved models can be easily used via MLflow’s <strong>command-line interface</strong> (CLI) or <strong>Web API</strong> for prediction serving</p>
</blockquote>
<h3 id="web-example">Web Example</h3>
<ol>
<li>
<p>Start the MLflow model serving endpoint:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>mlflow models serve --env-manager <span style="color:#204a87">local</span> -m <span style="color:#4e9a06">"models:/m-1abbea58e1cf442ab9412b7eae572523"</span> -p <span style="color:#0000cf;font-weight:bold">1234</span>
</span></span></code></pre></div></li>
<li>
<p>Send a prediction request via <code>curl</code>:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>curl http://localhost:1234/invocations -H <span style="color:#4e9a06">"Content-Type:application/json"</span> --data <span style="color:#4e9a06">'{
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">    "inputs": [
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">        [5.1, 3.5, 1.4, 0.2],
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">        [7.0, 3.2, 4.7, 1.4],
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">        [6.3, 3.3, 6.0, 2.5]
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">    ]
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">}'</span>
</span></span></code></pre></div></li>
<li>
<p>Observe the predictions output:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>{"predictions": [0, 1, 2]}
</span></span></code></pre></div></li>
</ol>
</section><section>
<h2 id="model-containerization-via-mlflow">Model containerization via MLflow</h2>
<ol>
<li>
<p>Build a Docker image for the model:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>mlflow models build-docker -m <span style="color:#4e9a06">"models:/m-1abbea58e1cf442ab9412b7eae572523"</span> -n iris-classifier-dt:latest
</span></span></code></pre></div></li>
<li>
<p>This should output something like:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>2025/11/12 16:50:16 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'
</span></span><span style="display:flex;"><span>2025/11/12 16:50:16 INFO mlflow.pyfunc.backend: Building docker image with name mlflow-pyfunc-servable
</span></span><span style="display:flex;"><span>[+] Building 254.3s (14/14) FINISHED                                                                                                                              docker:default
</span></span><span style="display:flex;"><span>=&gt; [internal] load build definition from Dockerfile                                                                                                                        0.5s
</span></span><span style="display:flex;"><span>=&gt; =&gt; transferring dockerfile: 1.00kB                                                                                                                                      0.0s
</span></span><span style="display:flex;"><span>=&gt; [internal] load metadata for docker.io/library/python:3.13.7-slim                                                                                                       6.2s
</span></span><span style="display:flex;"><span>=&gt; [auth] library/python:pull token for registry-1.docker.io                                                                                                               0.0s
</span></span><span style="display:flex;"><span>=&gt; [internal] load .dockerignore                                                                                                                                           0.3s
</span></span><span style="display:flex;"><span>=&gt; =&gt; transferring context: 2B                                                                                                                                             0.0s
</span></span><span style="display:flex;"><span>=&gt; [internal] load build context                                                                                                                                           0.4s
</span></span><span style="display:flex;"><span>=&gt; =&gt; transferring context: 5.14kB                                                                                                                                         0.0s
</span></span><span style="display:flex;"><span>=&gt; [1/8] FROM docker.io/library/python:3.13.7-slim@sha256:5f55cdf0c5d9dc1a415637a5ccc4a9e18663ad203673173b8cda8f8dcacef689                                                 6.5s
</span></span><span style="display:flex;"><span>=&gt; =&gt; resolve docker.io/library/python:3.13.7-slim@sha256:5f55cdf0c5d9dc1a415637a5ccc4a9e18663ad203673173b8cda8f8dcacef689                                                 0.1s
</span></span><span style="display:flex;"><span>=&gt; =&gt; sha256:5f55cdf0c5d9dc1a415637a5ccc4a9e18663ad203673173b8cda8f8dcacef689 10.37kB / 10.37kB                                                                            0.0s
</span></span><span style="display:flex;"><span>=&gt; =&gt; sha256:2be5d3cb08aa616c6e38d922bd7072975166b2de772004f79ee1bae59fe983dc 1.75kB / 1.75kB                                                                              0.0s
</span></span><span style="display:flex;"><span>=&gt; =&gt; sha256:7b444340715da1bb14bdb39c8557e0195455f5f281297723c693a51bc38a2c4a 5.44kB / 5.44kB                                                                              0.0s
</span></span><span style="display:flex;"><span>=&gt; =&gt; sha256:8c7716127147648c1751940b9709b6325f2256290d3201662eca2701cadb2cdf 29.78MB / 29.78MB                                                                            2.1s
</span></span><span style="display:flex;"><span>=&gt; =&gt; sha256:31fd2a94d72338ac6bbe103da6448d7e4cb7e7a29b9f56fa61d307b4395edf86 1.29MB / 1.29MB                                                                              0.7s
</span></span><span style="display:flex;"><span>=&gt; =&gt; sha256:66b685f2f76ba4e1e04b26b98a2aca385ea829c3b1ec637fbd82df8755973a60 11.74MB / 11.74MB                                                                            2.5s
</span></span><span style="display:flex;"><span>=&gt; =&gt; sha256:7d456e82f89bfe09aec396e93d830ba74fe0257fe2454506902adf46fb4377b3 250B / 250B                                                                                  1.3s
</span></span><span style="display:flex;"><span>=&gt; =&gt; extracting sha256:8c7716127147648c1751940b9709b6325f2256290d3201662eca2701cadb2cdf                                                                                   0.8s
</span></span><span style="display:flex;"><span>=&gt; =&gt; extracting sha256:31fd2a94d72338ac6bbe103da6448d7e4cb7e7a29b9f56fa61d307b4395edf86                                                                                   0.2s
</span></span><span style="display:flex;"><span>=&gt; =&gt; extracting sha256:66b685f2f76ba4e1e04b26b98a2aca385ea829c3b1ec637fbd82df8755973a60                                                                                   0.6s
</span></span><span style="display:flex;"><span>=&gt; =&gt; extracting sha256:7d456e82f89bfe09aec396e93d830ba74fe0257fe2454506902adf46fb4377b3                                                                                   0.0s
</span></span><span style="display:flex;"><span>=&gt; [2/8] RUN apt-get -y update &amp;&amp; apt-get install -y --no-install-recommends nginx                                                                                        20.5s
</span></span><span style="display:flex;"><span>=&gt; [3/8] WORKDIR /opt/mlflow                                                                                                                                               0.3s
</span></span><span style="display:flex;"><span>=&gt; [4/8] RUN pip install mlflow==3.5.0                                                                                                                                   162.1s
</span></span><span style="display:flex;"><span>=&gt; [5/8] COPY model_dir /opt/ml/model                                                                                                                                      0.9s
</span></span><span style="display:flex;"><span>=&gt; [6/8] RUN python -c "from mlflow.models import container as C; C._install_pyfunc_deps('/opt/ml/model', install_mlflow=False, enable_mlserver=False, env_manager='loca  27.6s
</span></span><span style="display:flex;"><span>=&gt; [7/8] RUN chmod o+rwX /opt/mlflow/                                                                                                                                      0.9s
</span></span><span style="display:flex;"><span>=&gt; [8/8] RUN rm -rf /var/lib/apt/lists/*                                                                                                                                   1.7s
</span></span><span style="display:flex;"><span>=&gt; exporting to image                                                                                                                                                     25.4s
</span></span><span style="display:flex;"><span>=&gt; =&gt; exporting layers                                                                                                                                                    24.9s
</span></span><span style="display:flex;"><span>=&gt; =&gt; writing image sha256:7b41a8c6bd049022abc8aeaaa41b7b60008c242fbc59c41073fc61daec05952d                                                                                0.1s
</span></span><span style="display:flex;"><span>=&gt; =&gt; naming to docker.io/library/iris-classifier-dt
</span></span></code></pre></div></li>
<li>
<p>Run the Docker container:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>docker run --rm -it --network host iris-classifier-dt:latest
</span></span></code></pre></div></li>
<li>
<p>Send a prediction request via <code>curl</code>:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>curl http://localhost:8000/invocations -H <span style="color:#4e9a06">"Content-Type:application/json"</span> --data <span style="color:#4e9a06">'{ "inputs": [[5.1, 3.5, 1.4, 0.2], [7.0, 3.2, 4.7, 1.4], [6.3, 3.3, 6.0, 2.5]] }'</span>
</span></span></code></pre></div></li>
<li>
<p>Observe the predictions output:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>{"predictions": [0, 1, 2]}
</span></span></code></pre></div></li>
</ol>

</section>
</section><section>


<section data-shortcode-section="">
<h2 id="model-registration-via-mlflow-pt-1">Model registration via MLflow (pt. 1)</h2>
<blockquote>
<p>One may <strong>register</strong> a model $\approx$ give it a <em>human-friendly name</em> + <em>versioning</em></p>
</blockquote>
<span class="fragment ">
  <ol>
<li>In the MLflow UI, go visit some logged model’s page, then click on the <strong>“Register”</strong> button
<img src="./mlflow-ui-model-register-1.png" alt=""></li>
</ol>
</span>
</section><section>
<h2 id="model-registration-via-mlflow-pt-2">Model registration via MLflow (pt. 2)</h2>
<ol start="2">
<li>The model will now appears in the <strong>“Models”</strong> section of the MLflow UI, with its <em>symbolic name</em>
<img src="./mlflow-ui-model-register-2.png" alt=""></li>
</ol>
</section><section>
<h2 id="model-registration-via-mlflow-pt-3">Model registration via MLflow (pt. 3)</h2>
<ol start="3">
<li>
<p>Click on the <strong>model name</strong> to see its available versions</p>
 <!-- ![](./mlflow-ui-model-register-3.png) -->
 <img src="./mlflow-ui-model-register-3.png" alt="" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain;">
<ul>
<li><em>multiple versions</em> of the same model may <em>coexist</em></li>
<li>each model’s version may be referred via the URI: <code>models:/&lt;model-name&gt;/&lt;version&gt;</code>
<ul>
<li>e.g. try to re-run the commands for predictions with model URI: <a href="models:/iris-classifier/1">models:/iris-classifier/1</a></li>
</ul>
</li>
<li>one may reference the last version of the model via the URI: <code>models:/&lt;model-name&gt;@latest</code></li>
</ul>
</li>
</ol>
</section><section>
<h2 id="model-registration-via-mlflow-pt-4">Model registration via MLflow (pt. 4)</h2>
<ol start="4">
<li>Details about some model’s version are inspectable in the UI as well
<img src="./mlflow-ui-model-register-4.png" alt=""></li>
</ol>

</section>
</section><section>


<section data-shortcode-section="">
<h2 id="a-realistic-mlops-scenario-with-mlflow-pt-1">A realistic MLOps scenario with MLflow (pt. 1)</h2>
<div class="container w-100 m-0 p-0">
    <div class="row "><div class="col "><p><img src="scikit-learn-pipeline.png" alt=""></p>
</div>
<div class="col "><ul>
<li>
<p>A <strong>ML workflow</strong> aimed at creating a <em>classifier</em> for the <a href="https://archive.ics.uci.edu/ml/datasets/adult">Adult Income dataset</a> via <strong>SciKit-Learn pipeline</strong></p>
<ul>
<li><em>goal</em>: predict whether a person makes over $50K a year based on census data</li>
</ul>
<ul>
<li><em>full-fledged</em> data pre-processing:
<ol>
<li>test-train split</li>
<li>missing values imputation</li>
<li>categorical features encoding</li>
<li>feature scaling</li>
<li>model selection via CV
<ul>
<li>among <em>logistic regression</em> and <em>random forests</em></li>
</ul>
</li>
<li>hyper-parameter tuning via grid search</li>
<li>etc.</li>
</ol>
</li>
</ul>
</li>
<li>
<p>Implemented as a <strong>Jupyter notebook</strong> + MLflow</p>
<ul>
<li>to discuss shortcomings and possible improvements</li>
</ul>
</li>
<li>
<p>Jupyter notebook available at: <a href="https://github.com/gciatto/example-mlops/blob/master/mlflow_census_demo.ipynb">https://github.com/gciatto/example-mlops/blob/master/mlflow_census_demo.ipynb</a></p>
</li>
</ul>
</div>
</div>
</div>
</section><section>
<h2 id="a-realistic-mlops-scenario-with-mlflow-pt-2">A realistic MLOps scenario with MLflow (pt. 2)</h2>
<ol>
<li>
<p>UI overview (metadata)
<img src="./mlflow-ui-adult-jupyter-1.png" alt=""></p>
<ul>
<li>notice the <em>nesting</em> of runs</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="a-realistic-mlops-scenario-with-mlflow-pt-2-1">A realistic MLOps scenario with MLflow (pt. 2)</h2>
<ol start="2">
<li>
<p>Comparing metrics across multiple runs
<img src="./mlflow-ui-adult-jupyter-2.png" alt=""></p>
<ul>
<li>notice the many <em>comparative charts</em> available</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="a-realistic-mlops-scenario-with-mlflow-pt-3">A realistic MLOps scenario with MLflow (pt. 3)</h2>
<ol start="3">
<li>
<p>Inspecting the winner model
<img src="./mlflow-ui-adult-jupyter-3.png" alt=""></p>
<ul>
<li>selected model: <em>Random Forest Classifier</em> (registered as <code>adult-best-random-forest</code>)</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="a-realistic-mlops-scenario-with-mlflow-pt-4">A realistic MLOps scenario with MLflow (pt. 4)</h2>
<h3 id="problems">Problems</h3>
<ul>
<li>
<p>Jupyter notebooks are <em>interactive</em> by nature</p>
<ul>
<li>making it hard to <strong>automate</strong> the workflow execution</li>
</ul>
</li>
<li>
<p>Executing the code is time-consuming: it requires a human operator to <strong>start</strong> the notebook and <strong>run</strong> all cells</p>
<ul>
<li>making it hard to <strong>schedule</strong> periodic runs (e.g. for model retraining)</li>
</ul>
</li>
<li>
<p>Pictures (if any) are commonly <em>embedded</em> in the notebook itself</p>
<ul>
<li>(not really the case in this example TBH, but a common practice)</li>
</ul>
</li>
<li>
<p>No code decomposition, poor version control</p>
<ul>
<li>making it hard to <strong>maintain</strong> and <strong>extend</strong> the code</li>
</ul>
</li>
<li>
<p>[<strong>Critical</strong>] Parameters are <em>hard-coded</em> in the notebook itself</p>
<ul>
<li>making it hard to <strong>tune</strong> the workflow behavior without modifying the code</li>
<li>making it hard to <strong>reproduce</strong> past runs with different parameter settings</li>
</ul>
</li>
</ul>
<span class="fragment ">
  <blockquote>
<p><strong>Solution:</strong> organize the code as an <em>MLflow Project</em> (see next slide)</p>
</blockquote>
</span>

</section>
</section><section>
<h2 id="mlflow-projects-pt-1">MLflow Projects (pt. 1)</h2>
<!-- https://mlflow.org/docs/latest/ml/projects/ -->
<blockquote>
<p>MLflow <strong>Projects</strong> provide a standard format for packaging and sharing <em>reproducible</em> data science code</p>
</blockquote>


<span class="fragment ">
  <ul>
<li>
<p>Assumption 1: <strong>files are structured</strong> in a specific way (decomposition of code into <em>multiple scripts</em>)</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#000">root-directory-name/</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#000">├── MLproject            </span><span style="color:#f8f8f8"> </span><span style="color:#8f5902;font-style:italic"># Project descriptor file</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#000">├── train.py             </span><span style="color:#f8f8f8"> </span><span style="color:#8f5902;font-style:italic"># Training script</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#000">├── test.py              </span><span style="color:#f8f8f8"> </span><span style="color:#8f5902;font-style:italic"># Test script</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">├── conda.yaml            # Optional</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#000">Conda environment (dependencies)</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">├── python_env.yaml       # Optional</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#000">Python environment (alternative to Conda)</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">└── data/                 # Optional</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#000">project data and assets</span><span style="color:#f8f8f8">
</span></span></span></code></pre></div><ul>
<li>notice that <code>train.py</code> and <code>test.py</code> are <strong>two separate scripts</strong>
<ul>
<li>each script is responsible for a <em>specific task</em> in the ML workflow</li>
<li>each script may be <em>invoked independently</em> of the others</li>
</ul>
</li>
</ul>
</li>
</ul>

</span>

</section><section>
<h2 id="mlflow-projects-pt-2">MLflow Projects (pt. 2)</h2>
<ul>
<li>Assumption 2: <strong>enviromental dependencies are declared</strong> in the <code>python_env.yaml</code> file (or in <code>conda.yaml</code>)
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">python</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"^3.13.7"</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">dependencies</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span>- <span style="color:#000">mlflow</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span>- <span style="color:#000">scikit-learn</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span>- <span style="color:#000">pandas</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span>- <span style="color:#000">matplotlib</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span>- <span style="color:#000">numpy</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span>- <span style="color:#000">requests</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span>- <span style="color:#000">jupyter</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span>- <span style="color:#000">seaborn</span><span style="color:#f8f8f8">
</span></span></span></code></pre></div></li>
</ul>
</section><section>
<h2 id="mlflow-projects-pt-3">MLflow Projects (pt. 3)</h2>
<ul>
<li>
<p>Assumption 3: <strong>ML tasks</strong> and <strong>their parameters</strong> are declared via the <code>MLproject</code> file</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#000">My ML Project</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Environment specification (choose one)</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">python_env</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#000">python_env.yaml</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># conda_env: conda.yaml</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># docker_env:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">#   image: python:3.9</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">entry_points</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span><span style="color:#204a87;font-weight:bold">main</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">        </span><span style="color:#204a87;font-weight:bold">parameters</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">param_file</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#000">path</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">param_num</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: float, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#0000cf;font-weight:bold">0.1</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">param_int</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: int, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#0000cf;font-weight:bold">100</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">        </span><span style="color:#204a87;font-weight:bold">command</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"python train.py --num {param_num} --int {param_int} {param_file}"</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span><span style="color:#204a87;font-weight:bold">test</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">        </span><span style="color:#204a87;font-weight:bold">parameters</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">param_str</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: str, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"hello"</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">param_uri</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#000">uri</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">        </span><span style="color:#204a87;font-weight:bold">command</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"python test.py --uri {param_uri} {param_str}"</span><span style="color:#f8f8f8">
</span></span></span></code></pre></div><ul>
<li>so that one can start <em>training</em> via:
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>mlflow run . -P <span style="color:#000">param_file</span><span style="color:#ce5c00;font-weight:bold">=</span>data/input.csv -P <span style="color:#000">param_num</span><span style="color:#ce5c00;font-weight:bold">=</span>0.2 -P <span style="color:#000">param_int</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#0000cf;font-weight:bold">200</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># if no -e &lt;entry-point&gt; is given, "main" is assumed by default</span>
</span></span></code></pre></div></li>
<li>so that one can start <em>testing</em> via:
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>mlflow run . -e <span style="color:#204a87">test</span> -P <span style="color:#000">param_str</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"world"</span> -P <span style="color:#000">param_uri</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"models:/my-model/1"</span>
</span></span></code></pre></div></li>
</ul>
</li>
</ul>
</section><section>
<h2 id="mlflow-projects-pt-4">MLflow Projects (pt. 4)</h2>
<ul>
<li>
<p>Assumption 4: entry-point scripts (<code>train.py</code>, etc.) are <strong>implemented</strong> to read all <em>relevant parameters</em> from <em>command-line</em></p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># train.py</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">import</span> <span style="color:#000">argparse</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#000">parser</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#000">argparse</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">ArgumentParser</span><span style="color:#000;font-weight:bold">()</span>
</span></span><span style="display:flex;"><span><span style="color:#000">parser</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">add_argument</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"file"</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#204a87">type</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87">str</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">help</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"Path to input data file"</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span><span style="color:#000">parser</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">add_argument</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"--num"</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#204a87">type</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87">float</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">default</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#0000cf;font-weight:bold">0.1</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">help</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"A numeric parameter"</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span><span style="color:#000">parser</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">add_argument</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"--int"</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#204a87">type</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87">int</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">default</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#0000cf;font-weight:bold">100</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">help</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"An integer parameter"</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span><span style="color:#000">args</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#000">parser</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">parse_args</span><span style="color:#000;font-weight:bold">()</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#204a87">print</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">f</span><span style="color:#4e9a06">"Training with data from: </span><span style="color:#4e9a06">{</span><span style="color:#000">args</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">file</span><span style="color:#4e9a06">}</span><span style="color:#4e9a06">"</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87">print</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">f</span><span style="color:#4e9a06">"Numeric parameter: </span><span style="color:#4e9a06">{</span><span style="color:#000">args</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">num</span><span style="color:#4e9a06">}</span><span style="color:#4e9a06">"</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87">print</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">f</span><span style="color:#4e9a06">"Integer parameter: </span><span style="color:#4e9a06">{</span><span style="color:#000">args</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">int</span><span style="color:#4e9a06">}</span><span style="color:#4e9a06">"</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># ... rest of the training code ...</span>
</span></span></code></pre></div></li>
<li>
<p>Assumption 5: entry-point scripts <strong>use</strong> <em>MLflow’s Tracking API</em> accordingly</p>
<ul>
<li>similar to what we saw in previous examples</li>
</ul>
</li>
</ul>
</section><section>


<section data-shortcode-section="">
<h2 id="mlflow-project-example-pt-1">MLflow Project <em>Example</em> (pt. 1)</h2>
<blockquote>
<p>Code at <a href="https://github.com/gciatto/example-mlops">https://github.com/gciatto/example-mlops</a></p>
</blockquote>
<p>(We also exemplify the usage of a <em>remote</em> MLflow Tracking Server)</p>
<ol>
<li>
<p>On machine with DNS name <code>my.mlflow.server.it</code>, <strong>clone</strong> the repository, and <strong>start MLflow server</strong> via <em>Docker Compose</em></p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># git clone https://github.com/gciatto/example-mlops.git</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># cd example-mlops</span>
</span></span><span style="display:flex;"><span>docker compose up -d --wait
</span></span></code></pre></div><ul>
<li>you may run Docker Compose on your local machine as well, hence using <a href="http://localhost:5000">http://localhost:5000</a> as tracking server</li>
</ul>
</li>
<li>
<p>On your <strong>local machine</strong>, clone the repository as well, then set the MLflow Tracking URI accordingly</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># git clone https://github.com/gciatto/example-mlops.git</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># cd example-mlops</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87">export</span> <span style="color:#000">MLFLOW_TRACKING_URI</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"http://my.mlflow.server.it:5000
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06"># or, on Windows (cmd):
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06"># set MLFLOW_TRACKING_URI=http://my.mlflow.server.it:5000
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06"># or, on Windows (PowerShell):
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06"># </span><span style="color:#000">$env</span><span style="color:#4e9a06">:MLFLOW_TRACKING_URI="</span>http://my.mlflow.server.it:5000<span style="color:#4e9a06">"
</span></span></span></code></pre></div><ul>
<li>in the example, I’ll be using <a href="http://pc-ciatto-area40.duckdns.org:5000">http://pc-ciatto-area40.duckdns.org:5000</a> as tracking server
<ul>
<li>not working outside VPN, sorry :)</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Again on your local machine, you may need to <strong>re-create</strong> the <em>Python environment</em> to run experiments</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>python -m venv .venv
</span></span><span style="display:flex;"><span><span style="color:#204a87">source</span> .venv/bin/activate <span style="color:#8f5902;font-style:italic"># on Windows: .venv\Scripts\activate</span>
</span></span><span style="display:flex;"><span>pip install -r requirements.txt
</span></span></code></pre></div></li>
</ol>
</section><section>
<h2 id="mlflow-project-example-pt-2">MLflow Project Example (pt. 2)</h2>
<ol start="4">
<li>
<p>Notice the <code>MLproject</code> file in the repository root, paying attention to the <strong>entry points</strong> defined therein, and their <em>parameters</em>:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#000">Census Income Prediction Demo</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">python_env</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#000">python.yaml</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">entry_points</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span><span style="color:#204a87;font-weight:bold">train</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">        </span><span style="color:#204a87;font-weight:bold">parameters</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">model_type</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: string, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"both"</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">test_size</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: float, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#0000cf;font-weight:bold">0.2</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">cv_splits</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: int, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#0000cf;font-weight:bold">3</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">random_state</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: int, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#0000cf;font-weight:bold">42</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">numeric_imputation_strategy</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: string, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"median"</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">numeric_scaling_with_mean</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: boolean, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#204a87;font-weight:bold">true</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">categorical_imputation_strategy</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: string, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"most_frequent"</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">ohe_handle_unknown</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: string, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"ignore"</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">sparse_threshold</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: float, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#0000cf;font-weight:bold">0.3</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">lr_max_iter</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: int, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#0000cf;font-weight:bold">1000</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">lr_C_values</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: string, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">'[0.1, 1.0, 10.0]'</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">lr_solvers</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: string, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">'["lbfgs"]'</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">rf_n_estimators</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: string, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">'[150, 300]'</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">rf_max_depths</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: string, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">'[null, 12]'</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">        </span><span style="color:#204a87;font-weight:bold">command</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#000;font-weight:bold">|</span><span style="color:#8f5902;font-style:italic">
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">            python train.py \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">                --model-type {model_type} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">                --test-size {test_size} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">                --cv-splits {cv_splits} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">                --random-state {random_state} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">                --numeric-imputation-strategy {numeric_imputation_strategy} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">                --numeric-scaling-with-mean {numeric_scaling_with_mean} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">                --categorical-imputation-strategy {categorical_imputation_strategy} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">                --ohe-handle-unknown {ohe_handle_unknown} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">                --sparse-threshold {sparse_threshold} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">                --lr-max-iter {lr_max_iter} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">                --lr-C-values {lr_C_values} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">                --lr-solvers {lr_solvers} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">                --rf-n-estimators {rf_n_estimators} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">                --rf-max-depths {rf_max_depths}</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span><span style="color:#204a87;font-weight:bold">test</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">        </span><span style="color:#204a87;font-weight:bold">parameters</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">run_id</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#000">string}</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">            </span><span style="color:#204a87;font-weight:bold">model_uri</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#000">string}</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">        </span><span style="color:#204a87;font-weight:bold">command</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"python test.py --run-id {run_id} --model-uri {model_uri}"</span><span style="color:#f8f8f8">
</span></span></span></code></pre></div><ul>
<li>use <code>python train.py --help</code> to see details about training script parameters</li>
<li>use <code>python test.py --help</code> to see details about testing script parameters</li>
<li>notice the <em>default values</em> for each parameter</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="mlflow-project-example-pt-3">MLflow Project Example (pt. 3)</h2>
<ol start="5">
<li>
<p>Still on your local machine, you may now <strong>run the training</strong> via MLflow Project API</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#000">EXPERIMENT_NAME</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"adult-classifier-</span><span style="color:#204a87;font-weight:bold">$(</span>date +<span style="color:#4e9a06">'%Y-%m-%d-%H-%M'</span><span style="color:#204a87;font-weight:bold">)</span><span style="color:#4e9a06">"</span>
</span></span><span style="display:flex;"><span>mlflow run -e train --env-manager<span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87">local</span> --experiment-name <span style="color:#4e9a06">"</span><span style="color:#000">$EXPERIMENT_NAME</span><span style="color:#4e9a06">"</span> . -P <span style="color:#000">model_type</span><span style="color:#ce5c00;font-weight:bold">=</span>both
</span></span></code></pre></div><ul>
<li>
<p>this may take some minutes, as the full model selection is performed via <em>CV</em> + <em>grid search</em></p>
<ul>
<li>you may run multiple times with different <code>model_type</code> parameter (either <code>logistic</code>, <code>random_forest</code>, instead of <code>both</code>)</li>
</ul>
</li>
<li>
<p>the <em>logs</em> of the training script will tell you which <strong>command</strong> to use for <em>testing the best model</em>:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>mlflow run -e <span style="color:#204a87">test</span> --env-manager<span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87">local</span> --experiment-name <span style="color:#000">$EXPERIMENT_NAME</span> . -P <span style="color:#000">run_id</span><span style="color:#ce5c00;font-weight:bold">=</span>&lt;TRAINING_RUN_ID&gt; -P <span style="color:#000">model_uri</span><span style="color:#ce5c00;font-weight:bold">=</span>models:/&lt;BEST_MODEL_ID&gt;
</span></span></code></pre></div></li>
</ul>
</li>
</ol>
</section><section>
<h2 id="mlflow-project-example-pt-4">MLflow Project Example (pt. 4)</h2>
<ol start="6">
<li>
<p>You may access the MLflow UI via the URL of the remote tracking server: <a href="http://my.mlflow.server.it:5000">http://my.mlflow.server.it:5000</a></p>
<ul>
<li>in our case: <a href="http://pc-ciatto-area40.duckdns.org:5000">http://pc-ciatto-area40.duckdns.org:5000</a></li>
</ul>
<p><img src="mlflow-ui-project-1.png" alt=""></p>
</li>
</ol>
</section><section>
<h2 id="mlflow-project-example-pt-5">MLflow Project Example (pt. 5)</h2>
<ol start="7">
<li>You may decide to <strong>re-run the experiment</strong> with different parameters, e.g.:
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">#&nbsp;to update the date-time in the experiment name, do:</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># EXPERIMENT_NAME="adult-classifier-$(date +'%Y-%m-%d-%H-%M')" </span>
</span></span><span style="display:flex;"><span>mlflow run -e train --env-manager<span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87">local</span> --experiment-name <span style="color:#4e9a06">"</span><span style="color:#000">$EXPERIMENT_NAME</span><span style="color:#4e9a06">"</span> . <span style="color:#4e9a06">\
</span></span></span><span style="display:flex;"><span>    -P <span style="color:#000">model_type</span><span style="color:#ce5c00;font-weight:bold">=</span>random_forest <span style="color:#4e9a06">\
</span></span></span><span style="display:flex;"><span>    -P <span style="color:#000">test_size</span><span style="color:#ce5c00;font-weight:bold">=</span>0.25 <span style="color:#4e9a06">\
</span></span></span><span style="display:flex;"><span>    -P <span style="color:#000">cv_splits</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#0000cf;font-weight:bold">5</span> <span style="color:#4e9a06">\
</span></span></span><span style="display:flex;"><span>    -P <span style="color:#000">random_state</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#0000cf;font-weight:bold">123</span>
</span></span></code></pre></div></li>
</ol>
</section><section>
<h2 id="mlflow-project-example-pt-6">MLflow Project Example (pt. 6)</h2>
<ol start="8">
<li>
<p>You may test the best model on the test set via:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">#&nbsp;reuse same EXPERIMENT_NAME as in training step</span>
</span></span><span style="display:flex;"><span>mlflow run -e <span style="color:#204a87">test</span> --env-manager<span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87">local</span> --experiment-name <span style="color:#000">$EXPERIMENT_NAME</span> . <span style="color:#4e9a06">\
</span></span></span><span style="display:flex;"><span>    -P <span style="color:#000">run_id</span><span style="color:#ce5c00;font-weight:bold">=</span>&lt;TRAINING_RUN_ID&gt; <span style="color:#4e9a06">\
</span></span></span><span style="display:flex;"><span>    -P <span style="color:#000">model_uri</span><span style="color:#ce5c00;font-weight:bold">=</span>models:/&lt;BEST_MODEL_ID&gt;
</span></span></code></pre></div><p>(look at the training script logs to find the exact command)</p>
<ul>
<li>this will result in a <em>new run</em> under the same experiment, with <strong>test</strong> <em>metrics logged</em> and <em>charts generated</em> accordingly:
<img src="./mlflow-ui-project-2.png" alt=""></li>
</ul>
</li>
</ol>

</section>
</section><section>


<section data-shortcode-section="">
<h2 id="llmops-with-mlflow">LLMOps with MLflow</h2>
<blockquote>
<p>MLflow may be used to track experiments involving <strong>Large Language Models (LLMs)</strong></p>
</blockquote>
<ul>
<li>
<p>MLflow’s <strong>Tracking API</strong> may be used to log:</p>
<ul>
<li><em>prompts</em> used for LLM queries</li>
<li><em>responses</em> obtained from LLMs</li>
<li><em>metrics</em> (e.g. tokens used, latency, etc.)</li>
<li><em>artifacts</em> (e.g. generated text files, images, etc.)</li>
<li><em>metadata</em> (e.g. model name, version, etc.)</li>
<li><em>parameters</em> (e.g. temperature, max tokens, etc.)</li>
</ul>
</li>
<li>
<p>Ad-hoc API is provided to Python programmers to express <strong>evaluation metrics</strong> for LLM-responses</p>
<ul>
<li>e.g. <em>LLM-as-a-Judge</em> for correctness scoring</li>
<li>e.g. other custom, <em>user-defined metrics</em> (Python functions)</li>
</ul>
</li>
<li>
<p>Support for <strong>multiple LLM providers</strong>, and their <em>client libraries</em></p>
<ul>
<li>there including <em>auto-logging</em> capabilities for some of them</li>
<li>e.g. OpenAI, LangChain, HuggingFace, etc.</li>
</ul>
</li>
<li>
<p>Support for annotating LLM-responses with <strong>human feedback</strong></p>
</li>
<li>
<p>Support for <strong>profiling data-flow</strong> back-and-forth between clients and LLM providers</p>
<ul>
<li>there including <em>agents using tools</em> as well</li>
<li>e.g. to monitor costs, latency, etc.</li>
</ul>
</li>
</ul>
</section><section>
<h2 id="main-idea-behind-llm-as-a-judge">Main idea behind LLM-as-a-Judge</h2>
<!-- ![](llm-as-a-judge.png) -->
<img src="./llm-as-a-judge.png" alt="" style="width: 100%; max-width: 95vw; max-height: 50vh; object-fit: contain;">
<ul>
<li>
<p>Use an LLM to <strong>evaluate</strong> the <em>quality</em> of responses generated by another LLM</p>
<ul>
<li>possibly via some <em>custom criteria</em> defined by the user</li>
<li>where the criteria are expressed in <em>natural language</em></li>
</ul>
</li>
<li>
<p>Think of criteria as <em>unit tests</em> for LLMs’ prompt–responses pairs</p>
<ul>
<li>such as: correctness, relevance, completeness, conciseness, formatting, etc.</li>
</ul>
</li>
<li>
<p>Examples:</p>
<ul>
<li><code>The response must be in English</code></li>
<li><code>The response must contain at least 3 examples</code></li>
<li>If <code>user question is asking for sensitive code</code>, then <code>response must kindly decline to answer</code></li>
</ul>
</li>
</ul>

</section>
</section><section>


<section data-shortcode-section="">
<h2 id="running-example-for-llm-based-application-pt-1">Running example for LLM-based Application (pt. 1)</h2>
<ul>
<li>For the final exam of a <strong>Software Engineering</strong> course, students must answer open questions about the course topics
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#4e9a06">CATEGORY</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">       QUESTION TEXT</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">                          WEIGHT (DIFFICULTY)</span><span style="color:#000;font-weight:bold">
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">############################################################################</span><span style="color:#000;font-weight:bold">
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">Definition</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">     What is computer science?</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">                  1</span><span style="color:#000;font-weight:bold">
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">Definition</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">     What is an algorithm?</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">                      1</span><span style="color:#000;font-weight:bold">
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">Definition</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">     "Difference among information</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06"> data</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06"> and representation"</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">1</span><span style="color:#000;font-weight:bold">
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">Definition</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">     What is software?</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">                          1</span><span style="color:#000;font-weight:bold">
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">Definition</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">     What is software engineering?</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">              1</span><span style="color:#000;font-weight:bold">
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">History</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">        What were software crises?</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">                 1</span><span style="color:#000;font-weight:bold">
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">Commonsense</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">    What makes software development costs rise?</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">1</span><span style="color:#000;font-weight:bold">
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">Commonsense</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">    What may delay software development?</span><span style="color:#000;font-weight:bold">,</span><span style="color:#4e9a06">       1</span><span style="color:#000;font-weight:bold">
</span></span></span></code></pre></div><ul>
<li>questions are known, but students are <strong>missing examples of good answers</strong></li>
</ul>
</li>
</ul>
<span class="fragment ">
  <blockquote>
<p><em>Idea!</em> Let’s generate <strong>examples of good answers</strong> via LLMs and provide students with them</p>
</blockquote>
<ul>
<li>possibly enhanced with <em>RAG techniques</em>, out of the <em>course’s teaching material</em>, to guarantee <em>coherence</em> with it
<ul>
<li>! not shown in the example !</li>
</ul>
</li>
<li>possibly enhanced with <em>search-engine tools</em> to enrich the answers with <em>up-to-date references</em></li>
</ul>
<span class="fragment ">
  <blockquote>
<p>MLflow may help in 1. selecting the <em>best models</em> and 2. <em>prompts</em>, assuming that 3. <em>evaluation metrics</em> are defined for generated answers</p>
</blockquote>
</span>
</span>
</section><section>
<h2 id="running-example-for-llm-based-application-pt-2">Running example for LLM-based Application (pt. 2)</h2>
<h4 id="many-different-prompt-templates-to-be-tried-for-answer-generation">Many different <strong>prompt templates</strong> to be <em>tried</em> for answer generation</h4>
<ul>
<li><em>system prompt</em>:
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>You are a university professor preparing model answers for a software engineering examination.
</span></span></code></pre></div></li>
</ul>
<div class="container w-100 m-0 p-0">
    <div class="row "><div class="col col-3"><ul>
<li><em>user</em> prompt 1 (<em>basic</em>):</li>
</ul>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>Category: {category}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Question: {question}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Difficulty: {weight}/4
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Provide a clear and accurate answer suitable for an exam context. 
</span></span><span style="display:flex;"><span>Be concise but comprehensive.
</span></span></code></pre></div></div>
<div class="col col-3"><ul>
<li><em>user</em> prompt 2 (<em>concise</em>):</li>
</ul>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>Category: {category}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Question: {question}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Weight: {weight}/4
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Answer the question above.
</span></span></code></pre></div></div>
<div class="col col-3"><ul>
<li><em>user</em> prompt 3 (<em>practical</em>):</li>
</ul>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>Category: {category}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Question: {question}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Difficulty: {weight}/4
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Provide an answer that:
</span></span><span style="display:flex;"><span>1. Explains the concept clearly
</span></span><span style="display:flex;"><span>2. Includes at least one concrete example or use case
</span></span><span style="display:flex;"><span>3. Relates to real-world software development scenarios
</span></span><span style="display:flex;"><span>4. Is easy to understand for someone learning the subject
</span></span></code></pre></div></div>
<div class="col col-3"><ul>
<li><em>user</em> prompt 4 (<em>academic</em>):</li>
</ul>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>Category: {category}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Difficulty: {weight}/4 (higher means more complex)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Question: {question}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Instructions:
</span></span><span style="display:flex;"><span>- Provide a rigorous, academically sound answer
</span></span><span style="display:flex;"><span>- Include relevant technical terminology
</span></span><span style="display:flex;"><span>- Reference key concepts and principles where appropriate
</span></span><span style="display:flex;"><span>- Structure your answer clearly with proper explanations
</span></span><span style="display:flex;"><span>- Aim for a comprehensive yet focused response suitable for academic evaluation
</span></span></code></pre></div></div>
</div>
</div>
<ul>
<li>system prompt addendum for <em>tools</em>:
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>Always use the provided web search tool to complement your answers with relevant and up-to-date links or references.
</span></span><span style="display:flex;"><span>In calling the tool, you should automatically infer the most relevant query based on the conversation so far.
</span></span></code></pre></div></li>
</ul>
</section><section>
<h2 id="running-example-for-llm-based-application-pt-3">Running example for LLM-based Application (pt. 3)</h2>
<h4 id="many-different-evaluation-criteria-to-be-tried-for-answer-assessment">Many different <strong>evaluation criteria</strong> to be <em>tried</em> for answer assessment</h4>
<p>General criteria:</p>
<ul>
<li>[Guideline] <code>english</code>: The answer should be in English.</li>
<li>[Guideline] <code>software_engineering_related</code>: The answer is correctly contextualizing the question within the domain of software engineering.</li>
<li>[Guideline] <code>reference_to_definition</code>: The answer should reference and/or quote relevant definitions for the concepts mentioned in the question.</li>
<li>[Guideline] <code>relevance_to_query</code>: The answer should be relevant to the question asked.</li>
<li>[Custom Score] <code>enough_words</code>: More than 10 words in the answer.</li>
<li>[Custom Score] <code>not_too_many_words</code>: Less than 1000 words in the answer.</li>
</ul>
<span class="fragment ">
  <p>Question-specific <em>correctness</em> criteria:</p>
<ul>
<li>For questions 1 (<code>What is computer science?</code>)
<ul>
<li>should mention “<em>study of computation</em>”, “<em>algorithms</em>”, “<em>data structures</em>”, “<em>software</em>”, “<em>hardware</em>”</li>
<li>should <strong>not</strong> argue that “computer science is the study of computers”</li>
</ul>
</li>
<li>For question 2 (<code>What is an algorithm?</code>)
<ul>
<li>should mention that:
<ol>
<li>“an algorithm is a <em>finite</em> sequence of steps/instructions”</li>
<li>“algorithms accept <em>inputs</em>”</li>
<li>“algorithms produce <em>outputs</em>”</li>
</ol>
</li>
<li>should <strong>not</strong> confuse algorithms with “programs” or “software”</li>
</ul>
</li>
<li>etc. for other questions</li>
</ul>
</span>
</section><section>
<h2 id="running-example-for-llm-based-application-pt-4">Running example for LLM-based Application (pt. 4)</h2>
<h3 id="example-question-1-with-prompt-1-and-all-criteria-on-model-gpt-41-mini">Example: Question 1, with <em>prompt 1</em> and <em>all criteria</em>, on model <code>gpt-4.1-mini</code></h3>
<ol>
<li>
<p>Question 1: <code>What is computer science?</code> (weight: <code>1</code>, category: <code>Definition</code>)</p>
</li>
<li>
<p>Prompt 1 (basic):</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>You are a university professor preparing model answers for a software engineering examination.
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>Category: Definition
</span></span><span style="display:flex;"><span>Question: What is computer science?
</span></span><span style="display:flex;"><span>Difficulty: 1/4
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Provide a clear and accurate answer suitable for an exam context. Be concise but comprehensive.
</span></span></code></pre></div></li>
<li>
<p>Generated answer:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>Computer science is the systematic study of computers and computational systems. 
</span></span><span style="display:flex;"><span>It involves understanding algorithms, data structures, software design, programming languages, 
</span></span><span style="display:flex;"><span>and the theoretical foundations of computation, as well as the practical aspects of developing 
</span></span><span style="display:flex;"><span>and applying software and hardware solutions to solve problems.
</span></span></code></pre></div></li>
<li>
<p>Evaluation results:</p>
<ul>
<li><code>english</code>: passed ✅</li>
<li><code>software_engineering_related</code>: failed ❌ (does not mention “software engineering”)</li>
<li><code>reference_to_definition</code>: failed ❌ (does not quote any definition)</li>
<li><code>relevance_to_query</code>: passed ✅</li>
<li><code>enough_words</code>: passed ✅</li>
<li><code>not_too_many_words</code>: passed ✅</li>
<li>Correctness (custom for question 1): passed ✅</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="running-example-for-llm-based-application-pt-5">Running example for LLM-based Application (pt. 5)</h2>
<h3 id="example-question-2-with-prompt-1-on-model-gpt-5-mini-with-agents--tools">Example: Question 2, with <em>prompt 1</em>, on model <code>gpt-5-mini</code>, with <strong>agents &amp; tools</strong></h3>
<ol>
<li>
<p>Question 2: <code>What is an algorithm?</code> (weight: <code>1</code>, category: <code>Definition</code>)</p>
</li>
<li>
<p>Prompt 1 (basic) + tools addendum:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>You are a university professor preparing model answers for a software engineering examination.
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>Always use the provided web search tool to complement your answers with relevant and up-to-date links or references.
</span></span><span style="display:flex;"><span>In calling the tool, you should automatically infer the most relevant query based on the conversation so far.
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>Category: Definition
</span></span><span style="display:flex;"><span>Question: What is an algorithm?
</span></span><span style="display:flex;"><span>Difficulty: 1/4
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Provide a clear and accurate answer suitable for an exam context. Be concise but comprehensive.
</span></span></code></pre></div></li>
<li>
<p>The tool:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#5c35cc;font-weight:bold">@tool</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">def</span> <span style="color:#000">web_search_tool</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">query</span><span style="color:#000;font-weight:bold">:</span> <span style="color:#204a87">str</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">max_results</span><span style="color:#000;font-weight:bold">:</span> <span style="color:#204a87">int</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#0000cf;font-weight:bold">3</span><span style="color:#000;font-weight:bold">)</span> <span style="color:#ce5c00;font-weight:bold">-&gt;</span> <span style="color:#204a87">str</span><span style="color:#000;font-weight:bold">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#4e9a06">"""
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">    Tool function for LLM to search the web and get formatted results.
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">    This combines search_web and format_search_results into a single tool.
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">    Args:
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">        query: Search query string
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">        max_results: Maximum number of results to return (default: 3)
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">        Markdown-formatted enumeration of search results where,
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">        for each result, the first line is the title of a Web page with an hyper-ref to the page's URL, 
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">        and the second line is a snippet/summary of the content.
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">    """</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">results</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#000">search_web</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">query</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">max_results</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#000">max_results</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">return</span> <span style="color:#000">format_search_results</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">results</span><span style="color:#000;font-weight:bold">)</span>
</span></span></code></pre></div></li>
</ol>
</section><section>
<h2 id="running-example-for-llm-based-application-pt-6">Running example for LLM-based Application (pt. 6)</h2>
<h3 id="example-question-2-with-prompt-1-on-model-gpt-5-mini-with-agents--tools-contd">Example: Question 2, with <em>prompt 1</em>, on model <code>gpt-5-mini</code>, with <strong>agents &amp; tools</strong> (cont’d)</h3>
<ol start="4">
<li>
<p>Generated intermediate <em>tool invocation</em>:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#000">web_search_tool</span><span style="color:#000;font-weight:bold">(</span><span style="color:#4e9a06">"What is an algorithm definition concise exam context computer science"</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">max_results</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#0000cf;font-weight:bold">3</span><span style="color:#000;font-weight:bold">)</span>
</span></span></code></pre></div><p>Result:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>Relevant Web search results:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">-</span> [<span style="color:#204a87;font-weight:bold">Wikipedia Algorithm - Wikipedia</span>](<span style="color:#c4a000">https://en.wikipedia.org/wiki/Algorithm</span>) 
</span></span><span style="display:flex;"><span>4 days ago - 
</span></span><span style="display:flex;"><span>In mathematics and computer science, an algorithm ...
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">-</span> [<span style="color:#204a87;font-weight:bold">Scribbr What is an algorithm in computer science?</span>](<span style="color:#c4a000">https://www.scribbr.com/frequently-asked-questions/algorithm-computer-science/</span>) 
</span></span><span style="display:flex;"><span>August 9, 2023 - 
</span></span><span style="display:flex;"><span>In computer science, an algorithm is a list of unambiguous instructions ...
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">-</span> ...
</span></span></code></pre></div></li>
</ol>
<ul>
<li><strong>Final</strong> generated answer:
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>An algorithm is a finite, well‑defined sequence of unambiguous instructions that, given specified input(s), 
</span></span><span style="display:flex;"><span>produces the desired output(s) and terminates after a finite number of steps.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Key properties (for exam answers)
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">-</span> Input and output: takes zero or more inputs and yields one or more outputs.
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">-</span> Finiteness (termination): completes in a finite number of steps for every valid input.
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">-</span> Definiteness (unambiguous): each step is precisely specified.
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">-</span> Effectiveness: each step is basic enough to be carried out in practice.
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">-</span> Correctness: when implemented, it solves the intended problem for all valid inputs.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Example (brief): the Euclidean algorithm for computing the greatest common divisor of two integers.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>References:
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">-</span> Wikipedia: Algorithm — &lt;https://en.wikipedia.org/wiki/Algorithm&gt;
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">-</span> Scribbr: What is an algorithm in computer science? — &lt;https://www.scribbr.com/frequently-asked-questions/algorithm-computer-science/&gt;
</span></span></code></pre></div></li>
</ul>

</section>
</section><section>


<section data-shortcode-section="">
<h2 id="exemplifying-mlflow-for-llm-applications-pt-1">Exemplifying MLflow for LLM Applications (pt. 1)</h2>
<blockquote>
<p>Code at <a href="https://github.com/gciatto/example-llmops">https://github.com/gciatto/example-llmops</a></p>
</blockquote>
<ol>
<li>
<p><strong>Clone</strong> the repository and <strong>start</strong> a local MLflow Tracking Server via Docker Compose:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>git clone https://github.com/gciatto/example-llmops.git
</span></span><span style="display:flex;"><span><span style="color:#204a87">cd</span> example-llmops
</span></span><span style="display:flex;"><span>docker-compose up -d --wait
</span></span></code></pre></div></li>
<li>
<p>Set the <em>environment variables</em> for <strong>MLflow Tracking Server URI</strong> and <strong>OpenAI API key</strong>:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#204a87">export</span> <span style="color:#000">MLFLOW_TRACKING_URI</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"http://localhost:5000"</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87">export</span> <span style="color:#000">OPENAI_API_KEY</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"sk-..."</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># on Windows (cmd):</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># set MLFLOW_TRACKING_URI=http://localhost:5000</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># set OPENAI_API_KEY=sk-...</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># on Windows (PowerShell):</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># $env:MLFLOW_TRACKING_URI="http://localhost:5000"</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># $env:OPENAI_API_KEY="sk-..."</span>
</span></span></code></pre></div></li>
<li>
<p><strong>Create and activate</strong> a Python virtual environment, then install dependencies:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>python -m venv .venv
</span></span><span style="display:flex;"><span><span style="color:#204a87">source</span> .venv/bin/activate <span style="color:#8f5902;font-style:italic"># on Windows: .venv\Scripts\activate</span>
</span></span><span style="display:flex;"><span>pip install -r requirements.txt
</span></span></code></pre></div></li>
</ol>
</section><section>
<h2 id="exemplifying-mlflow-for-llm-applications-pt-2">Exemplifying MLflow for LLM Applications (pt. 2)</h2>
<ol start="4">
<li>Have a look to the <strong>project structure</strong> (Docker and other irrelevant files are omitted):
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>example-llmops/
</span></span><span style="display:flex;"><span>├── MLproject                   <span style="color:#8f5902;font-style:italic"># MLflow Project descriptor file</span>
</span></span><span style="display:flex;"><span>├── register_all_prompts.py     <span style="color:#8f5902;font-style:italic"># Script to register prompt templates</span>
</span></span><span style="display:flex;"><span>├── generate_answers.py         <span style="color:#8f5902;font-style:italic"># Script to generate answers without agents/tools</span>
</span></span><span style="display:flex;"><span>├── generate_answers_with_agent.py <span style="color:#8f5902;font-style:italic"># Script to generate answers with agents/tools</span>
</span></span><span style="display:flex;"><span>├── evaluate_responses.py       <span style="color:#8f5902;font-style:italic"># Script to evaluate generated responses</span>
</span></span><span style="display:flex;"><span>├── prompts                     <span style="color:#8f5902;font-style:italic"># Directory with prompt templates</span>
</span></span><span style="display:flex;"><span>│   ├── academic.txt
</span></span><span style="display:flex;"><span>│   ├── basic.txt
</span></span><span style="display:flex;"><span>│   ├── concise.txt
</span></span><span style="display:flex;"><span>│   ├── practical.txt
</span></span><span style="display:flex;"><span>│   ├── system.txt
</span></span><span style="display:flex;"><span>│   └── tools.txt
</span></span><span style="display:flex;"><span>├── python_env.yaml             <span style="color:#8f5902;font-style:italic"># Python environment (dependencies)</span>
</span></span><span style="display:flex;"><span>└──  questions.csv              <span style="color:#8f5902;font-style:italic"># CSV file with input questions</span>
</span></span></code></pre></div></li>
</ol>
</section><section>
<h2 id="exemplifying-mlflow-for-llm-applications-pt-3">Exemplifying MLflow for LLM Applications (pt. 3)</h2>
<ol start="5">
<li>
<p>Notice the <code>MLproject</code> file in the repository root, paying attention to the <strong>entry points</strong> defined therein, and their <em>parameters</em>:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#000">quiz-answer-generator</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">python_env</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#000">python_env.yaml</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">entry_points</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">  </span><span style="color:#204a87;font-weight:bold">register_all_prompts</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span><span style="color:#204a87;font-weight:bold">command</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"python register_all_prompts.py"</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">  </span><span style="color:#204a87;font-weight:bold">evaluate_responses</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span><span style="color:#204a87;font-weight:bold">parameters</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">      </span><span style="color:#204a87;font-weight:bold">generation_run_id</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: str, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"none"</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">      </span><span style="color:#204a87;font-weight:bold">judge_model</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: str, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"openai:/gpt-4.1-mini"</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span><span style="color:#204a87;font-weight:bold">command</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"python evaluate_responses.py --generation-run-id {generation_run_id} --judge-model {judge_model}"</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">  </span><span style="color:#204a87;font-weight:bold">generate_answers</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span><span style="color:#204a87;font-weight:bold">parameters</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">      </span><span style="color:#204a87;font-weight:bold">prompt_template</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: str, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"basic"</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">      </span><span style="color:#204a87;font-weight:bold">max_questions</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: int, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>-<span style="color:#0000cf;font-weight:bold">1</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">      </span><span style="color:#204a87;font-weight:bold">model</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: str, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"gpt-4.1-mini"</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">      </span><span style="color:#204a87;font-weight:bold">temperature</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: float, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#0000cf;font-weight:bold">0.7</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">      </span><span style="color:#204a87;font-weight:bold">max_tokens</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: int, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#0000cf;font-weight:bold">500</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span><span style="color:#204a87;font-weight:bold">command</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#000;font-weight:bold">|</span><span style="color:#8f5902;font-style:italic">
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">      python generate_answers.py \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">        --prompt-template {prompt_template} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">        --max-questions {max_questions} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">        --model {model} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">        --temperature {temperature} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">        --max-tokens {max_tokens}</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">  </span><span style="color:#204a87;font-weight:bold">generate_answers_with_agent</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span><span style="color:#204a87;font-weight:bold">parameters</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">      </span><span style="color:#204a87;font-weight:bold">prompt_template</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: str, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"basic"</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">      </span><span style="color:#204a87;font-weight:bold">search_results_count</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: int, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#0000cf;font-weight:bold">3</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">      </span><span style="color:#204a87;font-weight:bold">max_questions</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: int, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>-<span style="color:#0000cf;font-weight:bold">1</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">      </span><span style="color:#204a87;font-weight:bold">model</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: str, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#4e9a06">"gpt-5-mini"</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">      </span><span style="color:#204a87;font-weight:bold">temperature</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: float, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#0000cf;font-weight:bold">0.7</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">      </span><span style="color:#204a87;font-weight:bold">max_tokens</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span>{<span style="color:#204a87;font-weight:bold">type: int, default</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#0000cf;font-weight:bold">1500</span>}<span style="color:#f8f8f8">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8">    </span><span style="color:#204a87;font-weight:bold">command</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8"> </span><span style="color:#000;font-weight:bold">|</span><span style="color:#8f5902;font-style:italic">
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">      python generate_answers_with_agent.py \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">        --prompt-template {prompt_template} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">        --search-results-count {search_results_count} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">        --max-questions {max_questions} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">        --model {model} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">        --temperature {temperature} \
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">        --max-tokens {max_tokens}</span><span style="color:#f8f8f8">
</span></span></span></code></pre></div><ul>
<li>use <code>python generate_answers.py --help</code> to see details about generation script parameters</li>
<li>use <code>python evaluate_responses.py --help</code> to see details about evaluation script parameters</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="exemplifying-mlflow-for-llm-applications-pt-4">Exemplifying MLflow for LLM Applications (pt. 4)</h2>
<ol start="6">
<li>Also give a look to the code in <code>evaluate_responses.py</code> script, where <em>evaluation criteria</em> are defined:
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">import</span> <span style="color:#000">mlflow</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">from</span> <span style="color:#000">mlflow.entities</span> <span style="color:#204a87;font-weight:bold">import</span> <span style="color:#000">Feedback</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">from</span> <span style="color:#000">mlflow.genai.scorers</span> <span style="color:#204a87;font-weight:bold">import</span> <span style="color:#000">Guidelines</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">scorer</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">RelevanceToQuery</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#5c35cc;font-weight:bold">@scorer</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">def</span> <span style="color:#000">enough_words</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">outputs</span><span style="color:#000;font-weight:bold">:</span> <span style="color:#204a87">dict</span><span style="color:#000;font-weight:bold">)</span> <span style="color:#ce5c00;font-weight:bold">-&gt;</span> <span style="color:#000">Feedback</span><span style="color:#000;font-weight:bold">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">text</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#000">outputs</span><span style="color:#000;font-weight:bold">[</span><span style="color:#4e9a06">'choices'</span><span style="color:#000;font-weight:bold">][</span><span style="color:#ce5c00;font-weight:bold">-</span><span style="color:#0000cf;font-weight:bold">1</span><span style="color:#000;font-weight:bold">][</span><span style="color:#4e9a06">'message'</span><span style="color:#000;font-weight:bold">][</span><span style="color:#4e9a06">'content'</span><span style="color:#000;font-weight:bold">]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">word_count</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#204a87">len</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">text</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">split</span><span style="color:#000;font-weight:bold">())</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">score</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#000">word_count</span> <span style="color:#ce5c00;font-weight:bold">&gt;=</span> <span style="color:#0000cf;font-weight:bold">10</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">rationale</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#000;font-weight:bold">(</span>
</span></span><span style="display:flex;"><span>        <span style="color:#4e9a06">f</span><span style="color:#4e9a06">"The response has more than 10 words: </span><span style="color:#4e9a06">{</span><span style="color:#000">word_count</span><span style="color:#4e9a06">}</span><span style="color:#4e9a06">"</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">if</span> <span style="color:#000">score</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">else</span> <span style="color:#4e9a06">f</span><span style="color:#4e9a06">"The response does not have enough words because it has less than 10 words: </span><span style="color:#4e9a06">{</span><span style="color:#000">word_count</span><span style="color:#4e9a06">}</span><span style="color:#4e9a06">."</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">return</span> <span style="color:#000">Feedback</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">value</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#000">score</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">rationale</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#000">rationale</span><span style="color:#000;font-weight:bold">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#5c35cc;font-weight:bold">@scorer</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">def</span> <span style="color:#000">not_too_many_words</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">outputs</span><span style="color:#000;font-weight:bold">:</span> <span style="color:#204a87">dict</span><span style="color:#000;font-weight:bold">)</span> <span style="color:#ce5c00;font-weight:bold">-&gt;</span> <span style="color:#000">Feedback</span><span style="color:#000;font-weight:bold">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">text</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#000">outputs</span><span style="color:#000;font-weight:bold">[</span><span style="color:#4e9a06">'choices'</span><span style="color:#000;font-weight:bold">][</span><span style="color:#ce5c00;font-weight:bold">-</span><span style="color:#0000cf;font-weight:bold">1</span><span style="color:#000;font-weight:bold">][</span><span style="color:#4e9a06">'message'</span><span style="color:#000;font-weight:bold">][</span><span style="color:#4e9a06">'content'</span><span style="color:#000;font-weight:bold">]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">word_count</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#204a87">len</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">text</span><span style="color:#ce5c00;font-weight:bold">.</span><span style="color:#000">split</span><span style="color:#000;font-weight:bold">())</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">score</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#000">word_count</span> <span style="color:#ce5c00;font-weight:bold">&lt;=</span> <span style="color:#0000cf;font-weight:bold">1000</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">rationale</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#000;font-weight:bold">(</span>
</span></span><span style="display:flex;"><span>        <span style="color:#4e9a06">f</span><span style="color:#4e9a06">"The response has less than 1000 words: </span><span style="color:#4e9a06">{</span><span style="color:#000">word_count</span><span style="color:#4e9a06">}</span><span style="color:#4e9a06">"</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">if</span> <span style="color:#000">score</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">else</span> <span style="color:#4e9a06">f</span><span style="color:#4e9a06">"The response has too many words: </span><span style="color:#4e9a06">{</span><span style="color:#000">word_count</span><span style="color:#4e9a06">}</span><span style="color:#4e9a06">."</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">return</span> <span style="color:#000">Feedback</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">value</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#000">score</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">rationale</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#000">rationale</span><span style="color:#000;font-weight:bold">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">def</span> <span style="color:#000">guidelines_model</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">model</span><span style="color:#000;font-weight:bold">:</span> <span style="color:#204a87">str</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#204a87;font-weight:bold">None</span><span style="color:#000;font-weight:bold">):</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">yield</span> <span style="color:#000">Guidelines</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">model</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#000">model</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">name</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"english"</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">guidelines</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"The answer should be in English."</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">yield</span> <span style="color:#000">Guidelines</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">model</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#000">model</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">name</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"software_engineering_related"</span><span style="color:#000;font-weight:bold">,</span>
</span></span><span style="display:flex;"><span>        <span style="color:#000">guidelines</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"The answer is correctly contextualizing the question within the domain of software engineering."</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">yield</span> <span style="color:#000">Guidelines</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">model</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#000">model</span><span style="color:#000;font-weight:bold">,</span> <span style="color:#000">name</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"reference_to_definition"</span><span style="color:#000;font-weight:bold">,</span>
</span></span><span style="display:flex;"><span>        <span style="color:#000">guidelines</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"The answer should reference and/or quote relevant definitions for the concepts mentioned in the question."</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">yield</span> <span style="color:#000">RelevanceToQuery</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">model</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#000">model</span><span style="color:#000;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">yield</span> <span style="color:#000">enough_words</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">yield</span> <span style="color:#000">not_too_many_words</span>
</span></span></code></pre></div></li>
</ol>
</section><section>
<h2 id="exemplifying-mlflow-for-llm-applications-pt-5">Exemplifying MLflow for LLM Applications (pt. 5)</h2>
<ol start="7">
<li>
<p>You may now <strong>register all prompt templates</strong> in a <em>new experiment</em> via:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#000">EXPERIMENT_ID</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"se-answers-</span><span style="color:#204a87;font-weight:bold">$(</span>date +<span style="color:#4e9a06">'%Y-%m-%d-%H-%M'</span><span style="color:#204a87;font-weight:bold">)</span><span style="color:#4e9a06">"</span>
</span></span><span style="display:flex;"><span>mlflow run -e register_all_prompts --env-manager<span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87">local</span> --experiment-name <span style="color:#000">$EXPERIMENT_ID</span> .
</span></span></code></pre></div></li>
<li>
<p>Look at the <strong>MLflow UI</strong> (“Prompts” main section) to see the <em>registered prompts</em>:
<img src="./mlflow-ui-llms-1a.png" alt=""></p>
</li>
</ol>
</section><section>
<h2 id="exemplifying-mlflow-for-llm-applications-pt-6">Exemplifying MLflow for LLM Applications (pt. 6)</h2>
<ol start="9">
<li>Clicking on a <em>prompt template</em>, you may see its details (versioning, content, etc.):
<img src="./mlflow-ui-llms-1b.png" alt=""></li>
</ol>
</section><section>
<h2 id="exemplifying-mlflow-for-llm-applications-pt-7">Exemplifying MLflow for LLM Applications (pt. 7)</h2>
<ol start="10">
<li>
<p>You may now <strong>generate answers</strong> via:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span>mlflow run -e generate_answers --env-manager<span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87">local</span> --experiment-name <span style="color:#000">$EXPERIMENT_ID</span> . -P <span style="color:#000">max_questions</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#0000cf;font-weight:bold">4</span>
</span></span></code></pre></div><p>(we put a limit of 4 questions to save time and costs)</p>
</li>
<li>
<p>Look at the <strong>MLflow UI</strong> (“Experiments” main section) to see the <em>generation runs</em>:
<img src="./mlflow-ui-llms-2.png" alt=""></p>
</li>
</ol>
</section><section>
<h2 id="exemplifying-mlflow-for-llm-applications-pt-8">Exemplifying MLflow for LLM Applications (pt. 8)</h2>
<ol start="12">
<li>
<p>Clicking on a <strong>trace</strong>, you may observe details about the <strong>interactions</strong> with the LLM provider:
<img src="./mlflow-ui-llms-3.png" alt=""></p>
<ul>
<li>notice the <em>logged prompts</em>, <em>responses</em>, <em>metrics</em>, etc.</li>
</ul>
</li>
</ol>
</section><section>
<h2 id="exemplifying-mlflow-for-llm-applications-pt-9">Exemplifying MLflow for LLM Applications (pt. 9)</h2>
<ol start="13">
<li>
<p>You may now <strong>evaluate generated answers</strong> via (see the output of generation runs for the exact command):</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># reuse same EXPERIMENT_ID as in generation step</span>
</span></span><span style="display:flex;"><span>mlflow run -e evaluate_responses --env-manager<span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87">local</span> --experiment-id &lt;EXPERIMENT_ID&gt; . -P <span style="color:#000">generation_run_id</span><span style="color:#ce5c00;font-weight:bold">=</span>&lt;GENERATION_RUN_ID&gt;
</span></span></code></pre></div><p>(this may take some time, as <code>Guidelines</code> evaluations are performed via further LLM queries)</p>
</li>
<li>
<p>Look at the <strong>MLflow UI</strong> (“Experiments” main section) to see the <em>evaluation runs</em>:
<img src="./mlflow-ui-llms-4.png" alt=""></p>
</li>
</ol>
</section><section>
<h2 id="exemplifying-mlflow-for-llm-applications-pt-10">Exemplifying MLflow for LLM Applications (pt. 10)</h2>
<ol start="15">
<li>
<p>You may now <strong>generate answers with agents &amp; tools</strong> via:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="nohighlight" data-noescape=""><span style="display:flex;"><span><span style="color:#000">EXPERIMENT_ID</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">"se-answers-agents-</span><span style="color:#204a87;font-weight:bold">$(</span>date +<span style="color:#4e9a06">'%Y-%m-%d-%H-%M'</span><span style="color:#204a87;font-weight:bold">)</span><span style="color:#4e9a06">"</span>
</span></span><span style="display:flex;"><span>mlflow run -e generate_answers_with_agent --env-manager<span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87">local</span> --experiment-name <span style="color:#000">$EXPERIMENT_ID</span> . -P <span style="color:#000">max_questions</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#0000cf;font-weight:bold">2</span>
</span></span></code></pre></div><p>(we put a limit of 2 questions to save time and costs)</p>
</li>
<li>
<p>In the <strong>MLflow UI</strong>, you may inspect which and how many <em>tool invocations</em> were performed:
<img src="./mlflow-ui-llms-5a.png" alt=""></p>
</li>
</ol>
</section><section>
<h2 id="exemplifying-mlflow-for-llm-applications-pt-11">Exemplifying MLflow for LLM Applications (pt. 11)</h2>
<ol start="17">
<li>Clicking on the “Details &amp; Timeline” tab, you may profile the entire <strong>data-flow</strong> back-and-forth between client and LLM provider:
<img src="./mlflow-ui-llms-5b.png" alt=""></li>
</ol>

</section>
</section><section>
<h1 id="talk-is-over">Talk is Over</h1>
<br>
<p>Compiled on: 2025-12-20
 — <a href="?print-pdf&amp;pdfSeparateFragments=false"><i class="fa fa-print" aria-hidden="true"></i> printable version</a></p>
<p><a href="#toc"><i class="fa fa-undo" aria-hidden="true"></i> back to ToC</a></p>
</section>

  


</div>
      

    </div>
<script type="text/javascript" src="/talk-2025-mlops/reveal-hugo/object-assign.js"></script>

<a href="/talk-2025-mlops/reveal-js/dist/print/" id="print-location" style="display: none;"></a>

<script type="application/json" id="reveal-hugo-site-params">{"custom_theme":"custom-theme.scss","custom_theme_compile":true,"custom_theme_options":{"enablesourcemap":true,"targetpath":"css/custom-theme.css"},"height":"1080","highlight_theme":"solarized-dark","history":true,"mermaid":[{}],"slide_number":true,"theme":"league","transition":"slide","transition_speed":"fast","width":"1920"}</script>
<script type="application/json" id="reveal-hugo-page-params">null</script>

<script src="/talk-2025-mlops/reveal-js/dist/reveal.js"></script>


  
  
  <script type="text/javascript" src="/talk-2025-mlops/reveal-js/plugin/markdown/markdown.js"></script>
  
  <script type="text/javascript" src="/talk-2025-mlops/reveal-js/plugin/highlight/highlight.js"></script>
  
  <script type="text/javascript" src="/talk-2025-mlops/reveal-js/plugin/zoom/zoom.js"></script>
  
  <script type="text/javascript" src="/talk-2025-mlops/reveal-js/plugin/notes/notes.js"></script>
  
  
  <script type="text/javascript" src="/talk-2025-mlops/reveal-js/plugin/notes/notes.js"></script>




<script type="text/javascript">
  
  
  function camelize(map) {
    if (map) {
      Object.keys(map).forEach(function(k) {
        newK = k.replace(/(\_\w)/g, function(m) { return m[1].toUpperCase() });
        if (newK != k) {
          map[newK] = map[k];
          delete map[k];
        }
      });
    }
    return map;
  }

  var revealHugoDefaults = { center: true, controls: true, history: true, progress: true, transition: "slide" };

  var revealHugoPlugins = {
    plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealZoom ]
   };
  var revealHugoSiteParams = JSON.parse(document.getElementById('reveal-hugo-site-params').innerHTML);
  var revealHugoPageParams = JSON.parse(document.getElementById('reveal-hugo-page-params').innerHTML);
  
  var options = Object.assign({},
    camelize(revealHugoDefaults),
    camelize(revealHugoSiteParams),
    camelize(revealHugoPageParams),
    camelize(revealHugoPlugins));
  Reveal.initialize(options);
</script>







  
  

  
  

  
  





    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      }
    };
</script>

<script type="text/javascript" id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-HwwvtgBNo3bZJJLYd8oVXjrBZt8cqVSpeBNS5n7C8IVInixGAoxmnlMuBnhbgrkm" crossorigin="anonymous"></script>

<script>
  if (/.*?(\?|&)print-pdf/.test(window.location.toString())) {
      var ytVideos = document.getElementsByTagName("iframe")
      for (let i = 0; i < ytVideos.length; i++) {
          var videoFrame = ytVideos[i]
          var isYouTube = /^https?:\/\/(www.)youtube\.com\/.*/.test(videoFrame.src)
          if (isYouTube) {
              console.log(`Removing ${videoFrame.src}`)
              var parent = videoFrame.parentElement
              videoFrame.remove()
              var p = document.createElement('p')
              p.append(
                  document.createTextNode(
                      "There was an embedded video here, but it is disabled in the printed version of the slides."
                  )
              )
              p.append(document.createElement('br'))
              p.append(
                  document.createTextNode(
                      `Visit instead ${
                          videoFrame.src
                      } or ${
                          videoFrame.src.replace(
                              /(^https?:\/\/(www.)youtube\.com)\/(embed\/)(\w+).*/,
                              "https://www.youtube.com/watch?v=$4"
                          )
                      }`
                  )
              )
              parent.appendChild(p)
          }
      }
  }
</script>


    
  

</body></html>